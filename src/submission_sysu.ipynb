{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codes for validating the WMH Challenge training Datasets. The algorithm won the WMH Challenge.\n",
    "#Codes are written by Mr. Hongwei Li (h.l.li@dundee.ac.uk), Mr. Gongfa Jiang and Miss. Zhaolei Wang from Sun Yat-sen University and University of Dundee.\n",
    "#\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import difflib\n",
    "import SimpleITK as sitk\n",
    "import scipy.spatial\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Cropping2D, ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "from evaluation import getDSC, getHausdorff, getLesionDetection, getAVD, getImages  #please download evaluation.py from the WMH website\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from show import imshow\n",
    "from scipy import ndimage\n",
    "#from sklearn.utils import class_weight\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go \n",
    "\n",
    "### ----define loss function for U-net ------------\n",
    "smooth = 1.\n",
    "def dice_coef_for_training(y_true, y_pred):\n",
    "    print(np.shape(y_pred))\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    print(np.shape(y_pred))\n",
    "    print(np.shape(y_true))\n",
    "    return -dice_coef_for_training(y_true, y_pred)\n",
    "\n",
    "def get_crop_shape(target, refer):\n",
    "        # width, the 3rd dimension\n",
    "        cw = (target.get_shape()[2] - refer.get_shape()[2]).value\n",
    "        assert (cw >= 0)\n",
    "        if cw % 2 != 0:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "        else:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2)\n",
    "        # height, the 2nd dimension\n",
    "        ch = (target.get_shape()[1] - refer.get_shape()[1]).value\n",
    "        assert (ch >= 0)\n",
    "        if ch % 2 != 0:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "        else:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "        return (ch1, ch2), (cw1, cw2)\n",
    "\n",
    "### ----define U-net architecture--------------\n",
    "def get_unet(img_shape = None):\n",
    "\n",
    "        dim_ordering = 'tf'\n",
    "        inputs = Input(shape = img_shape)\n",
    "        concat_axis = -1\n",
    "        ### the size of convolutional kernels is defined here    \n",
    "        conv1 = Convolution2D(64, 5, 5, activation='relu', border_mode='same', dim_ordering=dim_ordering, name='conv1_1')(inputs)\n",
    "        conv1 = Convolution2D(64, 5, 5, activation='relu', border_mode='same', dim_ordering=dim_ordering)(conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2), dim_ordering=dim_ordering)(conv1)\n",
    "        conv2 = Convolution2D(96, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(pool1)\n",
    "        conv2 = Convolution2D(96, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2), dim_ordering=dim_ordering)(conv2)\n",
    "\n",
    "        conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(pool2)\n",
    "        conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(conv3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2), dim_ordering=dim_ordering)(conv3)\n",
    "\n",
    "        conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(pool3)\n",
    "        conv4 = Convolution2D(256, 4, 4, activation='relu', border_mode='same', dim_ordering=dim_ordering)(conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2), dim_ordering=dim_ordering)(conv4)\n",
    "\n",
    "        conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(pool4)\n",
    "        conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(conv5)\n",
    "\n",
    "        up_conv5 = UpSampling2D(size=(2, 2), dim_ordering=dim_ordering)(conv5)\n",
    "        ch, cw = get_crop_shape(conv4, up_conv5)\n",
    "        crop_conv4 = Cropping2D(cropping=(ch,cw), dim_ordering=dim_ordering)(conv4)\n",
    "        up6 = merge([up_conv5, crop_conv4], mode='concat', concat_axis=concat_axis)\n",
    "        conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(up6)\n",
    "        conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(conv6)\n",
    "\n",
    "        up_conv6 = UpSampling2D(size=(2, 2), dim_ordering=dim_ordering)(conv6)\n",
    "        ch, cw = get_crop_shape(conv3, up_conv6)\n",
    "        crop_conv3 = Cropping2D(cropping=(ch,cw), dim_ordering=dim_ordering)(conv3)\n",
    "        up7 = merge([up_conv6, crop_conv3], mode='concat', concat_axis=concat_axis)\n",
    "        conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(up7)\n",
    "        conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(conv7)\n",
    "\n",
    "        up_conv7 = UpSampling2D(size=(2, 2), dim_ordering=dim_ordering)(conv7)\n",
    "        ch, cw = get_crop_shape(conv2, up_conv7)\n",
    "        crop_conv2 = Cropping2D(cropping=(ch,cw), dim_ordering=dim_ordering)(conv2)\n",
    "        up8 = merge([up_conv7, crop_conv2], mode='concat', concat_axis=concat_axis)\n",
    "        conv8 = Convolution2D(96, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(up8)\n",
    "        conv8 = Convolution2D(96, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(conv8)\n",
    "\n",
    "        up_conv8 = UpSampling2D(size=(2, 2), dim_ordering=dim_ordering)(conv8)\n",
    "        ch, cw = get_crop_shape(conv1, up_conv8)\n",
    "        crop_conv1 = Cropping2D(cropping=(ch,cw), dim_ordering=dim_ordering)(conv1)\n",
    "        up9 = merge([up_conv8, crop_conv1], mode='concat', concat_axis=concat_axis)\n",
    "        conv9 = Convolution2D(64, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(up9)\n",
    "        conv9 = Convolution2D(64, 3, 3, activation='relu', border_mode='same', dim_ordering=dim_ordering)(conv9)\n",
    "\n",
    "        ch, cw = get_crop_shape(inputs, conv9)\n",
    "        conv9 = ZeroPadding2D(padding=(ch, cw), dim_ordering=dim_ordering)(conv9)\n",
    "        conv10 = Convolution2D(1, 1, 1, activation='sigmoid', dim_ordering=dim_ordering)(conv9)\n",
    "        model = Model(input=inputs, output=conv10)\n",
    "        model.compile(optimizer=Adam(lr=(1e-4)*2), loss=dice_coef_loss, metrics=[dice_coef_for_training])\n",
    "\n",
    "        return model\n",
    "\n",
    "###----define prepocessing methods/tricks for different datasets------------------------\n",
    "def Utrecht_preprocessing(FLAIR_image, T1_image):\n",
    "\n",
    "    channel_num = 2\n",
    "    print(np.shape(FLAIR_image))\n",
    "    num_selected_slice = np.shape(FLAIR_image)[0]\n",
    "    image_rows_Dataset = np.shape(FLAIR_image)[1]\n",
    "    image_cols_Dataset = np.shape(FLAIR_image)[2]\n",
    "    T1_image = np.float32(T1_image)\n",
    "\n",
    "    brain_mask_FLAIR = np.ndarray((np.shape(FLAIR_image)[0],image_rows_Dataset, image_cols_Dataset), dtype=np.float32)\n",
    "    brain_mask_T1 = np.ndarray((np.shape(FLAIR_image)[0],image_rows_Dataset, image_cols_Dataset), dtype=np.float32)\n",
    "    imgs_two_channels = np.ndarray((num_selected_slice, rows_standard, cols_standard, channel_num), dtype=np.float32)\n",
    "    imgs_mask_two_channels = np.ndarray((num_selected_slice, rows_standard, cols_standard,1), dtype=np.float32)\n",
    "\n",
    "    # FLAIR --------------------------------------------\n",
    "    brain_mask_FLAIR[FLAIR_image >=thresh_FLAIR] = 1\n",
    "    brain_mask_FLAIR[FLAIR_image < thresh_FLAIR] = 0\n",
    "    for iii in range(np.shape(FLAIR_image)[0]):\n",
    "        brain_mask_FLAIR[iii,:,:] = scipy.ndimage.morphology.binary_fill_holes(brain_mask_FLAIR[iii,:,:])  #fill the holes inside brain\n",
    "    FLAIR_image = FLAIR_image[:, (image_rows_Dataset/2-rows_standard/2):(image_rows_Dataset/2+rows_standard/2), (image_cols_Dataset/2-cols_standard/2):(image_cols_Dataset/2+cols_standard/2)]\n",
    "    brain_mask_FLAIR = brain_mask_FLAIR[:, (image_rows_Dataset/2-rows_standard/2):(image_rows_Dataset/2+rows_standard/2), (image_cols_Dataset/2-cols_standard/2):(image_cols_Dataset/2+cols_standard/2)]\n",
    "    ###------Gaussion Normalization here\n",
    "    FLAIR_image -=np.mean(FLAIR_image[brain_mask_FLAIR == 1])      #Gaussion Normalization\n",
    "    FLAIR_image /=np.std(FLAIR_image[brain_mask_FLAIR == 1])\n",
    "    # T1 -----------------------------------------------\n",
    "    brain_mask_T1[T1_image >=thresh_T1] = 1\n",
    "    brain_mask_T1[T1_image < thresh_T1] = 0\n",
    "    for iii in range(np.shape(T1_image)[0]):\n",
    "        brain_mask_T1[iii,:,:] = scipy.ndimage.morphology.binary_fill_holes(brain_mask_T1[iii,:,:])  #fill the holes inside brain\n",
    "    T1_image = T1_image[:, (image_rows_Dataset/2-rows_standard/2):(image_rows_Dataset/2+rows_standard/2), (image_cols_Dataset/2-cols_standard/2):(image_cols_Dataset/2+cols_standard/2)]\n",
    "    brain_mask_T1 = brain_mask_T1[:, (image_rows_Dataset/2-rows_standard/2):(image_rows_Dataset/2+rows_standard/2), (image_cols_Dataset/2-cols_standard/2):(image_cols_Dataset/2+cols_standard/2)]\n",
    "    #------Gaussion Normalization\n",
    "    T1_image -=np.mean(T1_image[brain_mask_T1 == 1])      \n",
    "    T1_image /=np.std(T1_image[brain_mask_T1 == 1])\n",
    "    #---------------------------------------------------\n",
    "    FLAIR_image  = FLAIR_image[..., np.newaxis]\n",
    "    T1_image  = T1_image[..., np.newaxis]\n",
    "    imgs_two_channels = np.concatenate((FLAIR_image, T1_image), axis = 3)\n",
    "    print(np.shape(imgs_two_channels))\n",
    "    return imgs_two_channels\n",
    "\n",
    "def Utrecht_postprocessing(FLAIR_array, pred):\n",
    "    start_slice = 6\n",
    "    num_selected_slice = np.shape(FLAIR_array)[0]\n",
    "    image_rows_Dataset = np.shape(FLAIR_array)[1]\n",
    "    image_cols_Dataset = np.shape(FLAIR_array)[2]\n",
    "    original_pred = np.ndarray(np.shape(FLAIR_array), dtype=np.float32)\n",
    "    original_pred[:,(image_rows_Dataset-rows_standard)/2:(image_rows_Dataset+rows_standard)/2,(image_cols_Dataset-cols_standard)/2:(image_cols_Dataset+cols_standard)/2] = pred[:,:,:,0]\n",
    "    \n",
    "    original_pred[0:start_slice, :, :] = 0\n",
    "    original_pred[(num_selected_slice-start_slice-1):(num_selected_slice-1), :, :] = 0\n",
    "    return original_pred\n",
    "\n",
    "\n",
    "\n",
    "def GE3T_preprocessing(FLAIR_image, T1_image):\n",
    "\n",
    "  #  start_slice = 10\n",
    "    channel_num = 2\n",
    "    start_cut = 46\n",
    "    print(np.shape(FLAIR_image))\n",
    "    num_selected_slice = np.shape(FLAIR_image)[0]\n",
    "    image_rows_Dataset = np.shape(FLAIR_image)[1]\n",
    "    image_cols_Dataset = np.shape(FLAIR_image)[2]\n",
    "    FLAIR_image = np.float32(FLAIR_image)\n",
    "    T1_image = np.float32(T1_image)\n",
    "\n",
    "    brain_mask_FLAIR = np.ndarray((np.shape(FLAIR_image)[0],image_rows_Dataset, image_cols_Dataset), dtype=np.float32)\n",
    "    brain_mask_T1 = np.ndarray((np.shape(FLAIR_image)[0],image_rows_Dataset, image_cols_Dataset), dtype=np.float32)\n",
    "    imgs_two_channels = np.ndarray((num_selected_slice, rows_standard, cols_standard, channel_num), dtype=np.float32)\n",
    "    imgs_mask_two_channels = np.ndarray((num_selected_slice, rows_standard, cols_standard,1), dtype=np.float32)\n",
    "    FLAIR_image_suitable = np.ndarray((num_selected_slice, rows_standard, cols_standard), dtype=np.float32)\n",
    "    T1_image_suitable = np.ndarray((num_selected_slice, rows_standard, cols_standard), dtype=np.float32)\n",
    "\n",
    "    # FLAIR --------------------------------------------\n",
    "    brain_mask_FLAIR[FLAIR_image >=thresh_FLAIR] = 1\n",
    "    brain_mask_FLAIR[FLAIR_image < thresh_FLAIR] = 0\n",
    "    for iii in range(np.shape(FLAIR_image)[0]):\n",
    "  \n",
    "        brain_mask_FLAIR[iii,:,:] = scipy.ndimage.morphology.binary_fill_holes(brain_mask_FLAIR[iii,:,:])  #fill the holes inside brain\n",
    "        #------Gaussion Normalization\n",
    "    FLAIR_image -=np.mean(FLAIR_image[brain_mask_FLAIR == 1])      #Gaussion Normalization\n",
    "    FLAIR_image /=np.std(FLAIR_image[brain_mask_FLAIR == 1])\n",
    "\n",
    "    FLAIR_image_suitable[...] = np.min(FLAIR_image)\n",
    "    FLAIR_image_suitable[:, :, (cols_standard/2-image_cols_Dataset/2):(cols_standard/2+image_cols_Dataset/2)] = FLAIR_image[:, start_cut:start_cut+rows_standard, :]\n",
    "   \n",
    "    # T1 -----------------------------------------------\n",
    "    brain_mask_T1[T1_image >=thresh_T1] = 1\n",
    "    brain_mask_T1[T1_image < thresh_T1] = 0\n",
    "    for iii in range(np.shape(T1_image)[0]):\n",
    " \n",
    "        brain_mask_T1[iii,:,:] = scipy.ndimage.morphology.binary_fill_holes(brain_mask_T1[iii,:,:])  #fill the holes inside brain\n",
    "        #------Gaussion Normalization\n",
    "    T1_image -=np.mean(T1_image[brain_mask_T1 == 1])      #Gaussion Normalization\n",
    "    T1_image /=np.std(T1_image[brain_mask_T1 == 1])\n",
    "\n",
    "    T1_image_suitable[...] = np.min(T1_image)\n",
    "    T1_image_suitable[:, :, (cols_standard-image_cols_Dataset)/2:(cols_standard+image_cols_Dataset)/2] = T1_image[:, start_cut:start_cut+rows_standard, :]\n",
    "    #---------------------------------------------------\n",
    "    FLAIR_image_suitable  = FLAIR_image_suitable[..., np.newaxis]\n",
    "    T1_image_suitable  = T1_image_suitable[..., np.newaxis]\n",
    "    \n",
    "    imgs_two_channels = np.concatenate((FLAIR_image_suitable, T1_image_suitable), axis = 3)\n",
    "    print(np.shape(imgs_two_channels))\n",
    "    return imgs_two_channels\n",
    "\n",
    "def GE3T_postprocessing(FLAIR_array, pred):\n",
    "    start_slice = 11\n",
    "    start_cut = 46\n",
    "    num_selected_slice = np.shape(FLAIR_array)[0]\n",
    "    image_rows_Dataset = np.shape(FLAIR_array)[1]\n",
    "    image_cols_Dataset = np.shape(FLAIR_array)[2]\n",
    "    original_pred = np.ndarray(np.shape(FLAIR_array), dtype=np.float32)\n",
    "    original_pred[:, start_cut:start_cut+rows_standard,:] = pred[:,:, (rows_standard-image_cols_Dataset)/2:(rows_standard+image_cols_Dataset)/2,0]\n",
    "\n",
    "    original_pred[0:start_slice, :, :] = 0\n",
    "    original_pred[(num_selected_slice-start_slice-1):(num_selected_slice-1), :, :] = 0\n",
    "    return original_pred\n",
    "\n",
    "\n",
    "\n",
    "###---Here comes the main funtion--------------------------------------------\n",
    "###---Leave one patient out validation--------------------------------------------\n",
    "\n",
    "patient_num = 60\n",
    "patient_count = 0\n",
    "rows_standard = 200\n",
    "cols_standard = 200\n",
    "thresh_FLAIR = 70      #to mask the brain\n",
    "thresh_T1 = 30\n",
    "para_array = [[0.958, 0.958, 3], [1.00, 1.00, 3], [1.20, 0.977, 3]]    # parameters of the scanner\n",
    "para_array = np.array(para_array, dtype=np.float32)\n",
    "\n",
    "\t\n",
    "#read the dirs of test data \n",
    "input_dir_1 = 'raw/Utrecht'\n",
    "input_dir_2 = 'raw/Singapore'\n",
    "input_dir_3 = 'raw/GE3T'\n",
    "###---dir to save results---------\n",
    "outputDir = 'evaluation_result_LOOV'\n",
    "#-------------------------------------------\n",
    "dirs = os.listdir(input_dir_1) + os.listdir(input_dir_2) + os.listdir(input_dir_3)\n",
    "#All the slices and the corresponding patients id\n",
    "imgs_three_datasets_two_channels = np.load('imgs_three_datasets_two_channels.npy')\n",
    "imgs_mask_three_datasets_two_channels = np.load('imgs_mask_three_datasets_two_channels.npy')\n",
    "slices_patient_id_label = np.load('slices_patient_id_label.npy')\n",
    "\n",
    "\n",
    "for dir_name in dirs:\n",
    "\tprint('dir_name is:')\n",
    "\tprint(dir_name)\n",
    "\tif patient_count < 20:\n",
    "\t\tinputDir = input_dir_1\n",
    "\telif patient_count > 19 and patient_count < 40:\n",
    "\t\tinputDir = input_dir_2\n",
    "\telif patient_count > 39:\n",
    "\t\tinputDir = input_dir_3\n",
    "\tFLAIR_image = sitk.ReadImage(os.path.join(inputDir, dir_name, 'pre', 'FLAIR.nii.gz'))\n",
    "\tT1_image = sitk.ReadImage(os.path.join(inputDir, dir_name, 'pre', 'T1.nii.gz'))\n",
    "\tFLAIR_array = sitk.GetArrayFromImage(FLAIR_image)\n",
    "\tT1_array = sitk.GetArrayFromImage(T1_image)\n",
    "\t#Proccess testing data-----\n",
    "\tpara_FLAIR = np.ndarray((1,3), dtype=np.float32)\n",
    "\tpara_FLAIR_ = FLAIR_image.GetSpacing()\n",
    "\tpara_FLAIR[0,0] = round(para_FLAIR_[0],3)   # get spacing parameters of the data\n",
    "\tpara_FLAIR[0,1] = round(para_FLAIR_[1],3)  \n",
    "\tpara_FLAIR[0,2] = round(para_FLAIR_[2],3) \n",
    "\tif np.array_equal(para_FLAIR[0], para_array[0]) :\n",
    "\t\tprint('From Utrecht!')\n",
    "\t\timgs_test = Utrecht_preprocessing(FLAIR_array, T1_array)\n",
    "\telif np.array_equal(para_FLAIR[0], para_array[1]):\n",
    "\t\tprint('From Singapore!')\n",
    "\t\timgs_test = Utrecht_preprocessing(FLAIR_array, T1_array)\n",
    "\telif np.array_equal(para_FLAIR[0], para_array[2]):\n",
    "\t\tprint('From GE3T!')\n",
    "\t \timgs_test = GE3T_preprocessing(FLAIR_array, T1_array)\n",
    "\n",
    "\t###---train u-net models-------------------------------------------------------------------------------\n",
    "\ttraining_index = slices_patient_id_label != patient_count\n",
    "\ttest_index = slices_patient_id_label == patient_count\n",
    "\tdim_training = sum(training_index)\n",
    "\tdim_test = sum(test_index)\n",
    "\tprint('the dim of training set:')\n",
    "\tprint(dim_training[0])\n",
    "\timgs_train = np.ndarray((dim_training[0], rows_standard, cols_standard, 2), dtype=np.float32)\n",
    "\timgs_test_selected = np.ndarray((dim_test[0], rows_standard, cols_standard, 2), dtype=np.float32)\n",
    "\n",
    "\timgs_mask_train = np.ndarray((dim_training[0], rows_standard, cols_standard, 1), dtype=np.float32)\n",
    "\timgs_mask_test_selected = np.ndarray((dim_test[0], rows_standard, cols_standard, 1), dtype=np.float32)\n",
    "\tcount_index_train = 0\n",
    "\tcount_index_test = 0\n",
    "\tfor iii in range(training_index.shape[0]):\n",
    "\t\tif training_index[iii] == 1:\n",
    "\t\t\timgs_train[count_index_train, ...] = imgs_three_datasets_two_channels[iii, ...]\n",
    "\t\t\timgs_mask_train[count_index_train, ...] = imgs_mask_three_datasets_two_channels[iii, ...]\n",
    "\t\t\tcount_index_train = count_index_train + 1\n",
    "\t\tif training_index[iii] == 0:\n",
    "\t\t\timgs_test_selected[count_index_test, ...] = imgs_three_datasets_two_channels[iii, ...]\n",
    "\t\t\timgs_mask_test_selected[count_index_test, ...] = imgs_mask_three_datasets_two_channels[iii, ...]\n",
    "\t\t\tcount_index_test = count_index_test + 1\n",
    "\t\n",
    "\tprint('training dataset dimension:')\n",
    "\tprint(imgs_train.shape[0])\n",
    "\timg_shape=(rows_standard, cols_standard, 2)\n",
    "\t\n",
    "\t\n",
    "\tprint('-'*30)\n",
    "\tprint('Fitting model...')\n",
    "\tprint('-'*30)\n",
    "    ###---parameters of training are set here------------------------------------\n",
    "\tensemble_parameter = 3\n",
    "\tmodel = get_unet(img_shape)\n",
    "\tpred = model.predict(imgs_test, batch_size=1,verbose=1)\n",
    "\tpred = np.ndarray(np.shape(pred), dtype=np.float32)\n",
    "\t###---ensemble model --------------------------\n",
    "\tfor iiii in range(ensemble_parameter):\n",
    "\t\tmodel = get_unet(img_shape)\n",
    "\t\tmodel_checkpoint = ModelCheckpoint('weights_three_datasets_two_channels_LOOV_'+str(iiii)+'.h5', save_best_only=False, period = 2)\n",
    "\t\t#model.fit(imgs_train, imgs_mask_train, batch_size=30, nb_epoch= 5, verbose=1, shuffle=True, validation_split=0.0, callbacks=[model_checkpoint])\n",
    "\t\t#model.save('weights_three_datasets_two_channels_LOOV_'+str(iiii)+'.h5')\n",
    "\t\tmodel.load_weights('weights_three_datasets_two_channels_LOOV_'+str(iiii)+'.h5')\n",
    "\t\tpred_temp = model.predict(imgs_test, batch_size=1,verbose=1)\n",
    "\t\tpred = pred + pred_temp\n",
    "\tpred = pred/int(ensemble_parameter)\n",
    "\tpred[pred[...,0] > 0.5] = 1      #thresholding \n",
    "\tpred[pred[...,0] <= 0.5] = 0\n",
    "\n",
    "\n",
    "\t#Postprocessing\n",
    "\tif np.array_equal(para_FLAIR[0], para_array[0]): \t\t\n",
    "\t\tprint('Utrecht!')\n",
    "\t\toriginal_pred = Utrecht_postprocessing(FLAIR_array, pred)\n",
    "\telif np.array_equal(para_FLAIR[0], para_array[1]):\n",
    "\t\tprint('Singapore!')\n",
    "\t\toriginal_pred = Utrecht_postprocessing(FLAIR_array, pred)\n",
    "\telif np.array_equal(para_FLAIR[0], para_array[2]):\n",
    "\t\tprint('GE3T!')\n",
    "\t\toriginal_pred = GE3T_postprocessing(FLAIR_array, pred)\n",
    "\t\n",
    "\tif not os.path.exists(outputDir):\n",
    "\t\tos.mkdir(outputDir)\n",
    "\tfilename_resultImage = os.path.join(outputDir, 'result.nii.gz')\n",
    "\tsitk.WriteImage(sitk.GetImageFromArray(original_pred), filename_resultImage )\n",
    "\tfilename_testImage = os.path.join(inputDir, dir_name, 'wmh.nii.gz')\n",
    "\ttestImage, resultImage = getImages(filename_testImage, filename_resultImage)\n",
    "\tdsc = getDSC(testImage, resultImage)\n",
    "\tavd = getAVD(testImage, resultImage) \n",
    "\th95 = getHausdorff(testImage, resultImage)\n",
    "\trecall, f1 = getLesionDetection(testImage, resultImage)\n",
    "\tprint('Result of patient '+str(patient_count))    \n",
    "\tprint('Dice',                dsc,       '(higher is better, max=1)')\n",
    "\tprint('HD',                  h95, 'mm',  '(lower is better, min=0)')\n",
    "\tprint('AVD',                 avd,  '%',  '(lower is better, min=0)')\n",
    "\tprint('Lesion detection', recall,       '(higher is better, max=1)')\n",
    "\tprint('Lesion F1',            f1,       '(higher is better, max=1)')\n",
    "#Save result-------------------------------------------------------\t\n",
    "\tresult_output_dir = os.path.join(outputDir,dir_name)  #directory for images\n",
    "\tif not os.path.exists(result_output_dir):\n",
    "\t\tos.mkdir(result_output_dir)\n",
    "\tnp.save(os.path.join(result_output_dir,'dsc.npy'), dsc)\n",
    "\tnp.save(os.path.join(result_output_dir,'avd.npy'), avd)\n",
    "\tnp.save(os.path.join(result_output_dir,'h95.npy'), h95)\n",
    "\tnp.save(os.path.join(result_output_dir,'recall.npy'), recall)\n",
    "\tnp.save(os.path.join(result_output_dir,'f1.npy'), f1)\n",
    "#-------------------------------------------------------------------\n",
    "\tfor iii in range(np.shape(imgs_test_selected)[0]):\n",
    "\t\tprint('saving image:'+ str(iii)+' of patient '+str(patient_count))\n",
    "\t\tpos_index = np.int32(np.where(imgs_mask_test_selected[iii]==1))\n",
    "\t\tpred_pos_index = np.array(np.where(pred[iii]>.9))\n",
    "\t\tinsect_index = np.int32(np.where(np.logical_and(pred[iii]>.5, imgs_mask_test_selected[iii]==1)))\n",
    "\t\tpred_mask = np.zeros([imgs_mask_test_selected[iii].shape[0], imgs_mask_test_selected[iii].shape[1], 3], dtype=np.float32)\n",
    "\t\tpred_mask[pos_index[0], pos_index[1], 0] = 1.\n",
    "\t\tpred_mask[pred_pos_index[0], pred_pos_index[1], ...] = 1.\n",
    "\t\tpred_mask[insect_index[0], insect_index[1], 0] = 0.\n",
    "\t\tpred_mask[insect_index[0], insect_index[1], 1] = 1.\n",
    "\t\tpred_mask[insect_index[0], insect_index[1], 2] = 0.\n",
    "\t\t\n",
    "\t\tseg_img = np.copy(imgs_test_selected[iii,:,:,0:1]) \t\n",
    "\t\tseg_img[imgs_mask_test_selected[iii]==1] = np.max(seg_img)\n",
    "\t\timshow(imgs_test_selected[iii,:,:,0],seg_img[:,:,0],pred_mask,pred[iii,:,:,0],title=['test image','ground truth','prediction','heat map'])\n",
    "\t\tplt.savefig(os.path.join(result_output_dir, str(iii) + '_pred.png'))\t\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "\tpatient_count = patient_count+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
