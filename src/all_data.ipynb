{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,time\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "inputDir = '../data/train'\n",
    "testDir = '../data/validation'\n",
    "outputDir = 'output'\n",
    "from random import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myshow(img, title=None, margin=0.05, dpi=100):\n",
    "    nda = sitk.GetArrayViewFromImage(img)\n",
    "    spacing = img.GetSpacing()\n",
    "        \n",
    "    if nda.ndim == 3:\n",
    "        # fastest dim, either component or x\n",
    "        c = nda.shape[-1]\n",
    "        \n",
    "        # the the number of components is 3 or 4 consider it an RGB image\n",
    "        if not c in (3,4):\n",
    "            nda = nda[nda.shape[0]//2,:,:]\n",
    "    \n",
    "    elif nda.ndim == 4:\n",
    "        c = nda.shape[-1]\n",
    "        \n",
    "        if not c in (3,4):\n",
    "            raise Runtime(\"Unable to show 3D-vector Image\")\n",
    "            \n",
    "        # take a z-slice\n",
    "        nda = nda[nda.shape[0]//2,:,:,:]\n",
    "            \n",
    "    ysize = nda.shape[0]\n",
    "    xsize = nda.shape[1]\n",
    "      \n",
    "    # Make a figure big enough to accommodate an axis of xpixels by ypixels\n",
    "    # as well as the ticklabels, etc...\n",
    "    figsize = (4 + margin) * ysize / dpi, (4 + margin) * xsize / dpi\n",
    "\n",
    "    fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "    # Make the axis the right size...\n",
    "    ax = fig.add_axes([margin, margin, 1 - 2*margin, 1 - 2*margin])\n",
    "   \n",
    "    extent = (0, xsize*spacing[1], ysize*spacing[0], 0)\n",
    "    \n",
    "    t = ax.imshow(nda,extent=extent,interpolation=None)\n",
    "    \n",
    "    if nda.ndim == 2:\n",
    "        t.set_cmap(\"gray\")\n",
    "    \n",
    "    if(title):\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows =240\n",
    "img_cols =240\n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "batchSize = 20\n",
    "batchShape = (batchSize, 240,240, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(imgs):\n",
    "#   print(\"pree\",imgs.shape, imgs.shape[:-1])\n",
    "    imgs_p = np.ndarray((imgs.shape[0],img_rows, img_cols,imgs.shape[-1]), dtype=np.uint8)\n",
    "#     print(\"imgs.shape[0]\",imgs.shape[0])\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i],(img_cols, img_rows,imgs.shape[-1]), preserve_range=True)\n",
    "  \n",
    "#   print(\"imgs_p\",imgs_p.shape)\n",
    "    return imgs_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData( inputDir,city, padding=0 ):\n",
    "    imageflairFilenames = glob.glob(os.path.join(inputDir, city, \"*\",\"pre\",\"FLAIR.nii.gz\"))\n",
    "    imageT1Filenames = glob.glob(os.path.join(inputDir, city, \"*\",\"pre\",\"T1.nii.gz\"))\n",
    "    labelFilenames= glob.glob(os.path.join(inputDir, city, \"*\",\"wmh.nii.gz\"))\n",
    "    images = None # shape: (numImages, z, y, x, channels=1)\n",
    "    labels = None\n",
    "    masks  = None\n",
    "    print(len(imageflairFilenames))\n",
    "    for imageflairFilenames, imageT1Filenames, labelFilenames in zip(imageflairFilenames, imageT1Filenames, labelFilenames):\n",
    "        # Load the images\n",
    "        flairImage = sitk.ReadImage(imageflairFilenames)\n",
    "        T1Image = sitk.ReadImage(imageT1Filenames)\n",
    "        labelImage = sitk.ReadImage(labelFilenames)\n",
    "        # Convert to arrays\n",
    "        flairArray = np.pad(sitk.GetArrayFromImage(flairImage), [(0,0),(padding,padding),(padding,padding)], 'constant')\n",
    "#         flairArray = preprocess(flairArray)\n",
    "        T1Array = np.pad(sitk.GetArrayFromImage(T1Image), [(0,0),(padding,padding),(padding,padding)], 'constant')\n",
    "#         T1Array = preprocess(T1Array)\n",
    "        labelArray = np.pad(sitk.GetArrayFromImage(labelImage), [(0,0),(padding,padding),(padding,padding)], 'constant')\n",
    "#         labelArray = preprocess(labelArray)\n",
    "        maskArray = labelArray > 0\n",
    "        print(\"flairArray\",flairArray.shape)\n",
    "        print(\"T1Array\",T1Array.shape)\n",
    "        print(\"labelArray\",labelArray.shape)\n",
    "        print(\"maskArray\",maskArray.shape)\n",
    "        # Add to the images/labels array\n",
    "        if images is None:\n",
    "            images = flairArray.reshape([1] + list(flairArray.shape) + [1])\n",
    "            images = np.concatenate([images, T1Array.reshape([1] + list(T1Array.shape) + [1])], axis=4)\n",
    "            labels = labelArray.reshape([1] + list(labelArray.shape) + [1])\n",
    "            masks  = maskArray.reshape([1] + list(maskArray.shape) + [1])\n",
    "        else:\n",
    "            tempArray = np.concatenate([flairArray.reshape([1] + list(flairArray.shape) + [1]), T1Array.reshape([1] + list(T1Array.shape) + [1])], axis=4)\n",
    "            print(\"tempArray:\",tempArray.shape,\"images:\",images.shape)\n",
    "            images = np.concatenate([images, tempArray])\n",
    "            \n",
    "            labels = np.concatenate([labels, labelArray.reshape([1] + list(labelArray.shape) + [1])])\n",
    "            masks  = np.concatenate([masks, maskArray.reshape([1] + list(maskArray.shape) + [1])])\n",
    "                    \n",
    "    return images, labels, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city = \"Amsterdam\"\n",
    "# testImages, testLabels, testMasks = loadData(testDir,city)\n",
    "# testNonZeroIdx = np.nonzero(testMasks)\n",
    "# trainImages, trainLabels, trainMasks = loadData(inputDir,city)\n",
    "# trainNonZeroIdx = np.nonzero(testMasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = np.empty([5, 2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]]\n",
    "list2 = [[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]]\n",
    "qq = np.array(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq = np.concatenate([pp,np.asarray(list2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 2, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-66680339e416>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-66680339e416>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    np.append(qq,[[1, 2, 3], [[4, 5, 6], [7, 8, 9]], axis=0)\u001b[0m\n\u001b[1;37m                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "np.append(qq,[[1, 2, 3], [[4, 5, 6], [7, 8, 9]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "flairArray (48, 232, 256)\n",
      "T1Array (48, 232, 256)\n",
      "labelArray (48, 232, 256)\n",
      "maskArray (48, 232, 256)\n",
      "flairArray (48, 256, 232)\n",
      "T1Array (48, 256, 232)\n",
      "labelArray (48, 256, 232)\n",
      "maskArray (48, 256, 232)\n",
      "tempArray: (1, 48, 256, 232, 2) images: (1, 48, 232, 256, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-246b8bf93b65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows_standard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols_standard\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcity\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcities\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtestImages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestMasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestDir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtestNonZeroIdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestMasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtrainImages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainMasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputDir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-22158398fde6>\u001b[0m in \u001b[0;36mloadData\u001b[1;34m(inputDir, city, padding)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mtempArray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mflairArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflairArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT1Array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT1Array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tempArray:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtempArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"images:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtempArray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "rows_standard, cols_standard = 200,200\n",
    "channel_num = 2\n",
    "cities = [\"Singapore\",\"Utrecht\",\"Amsterdam\"]\n",
    "X= np.empty([2, rows_standard, cols_standard,2])\n",
    "y= np.empty([2, rows_standard, cols_standard,1])\n",
    "for city in cities:\n",
    "    testImages, testLabels, testMasks = loadData(testDir,city)\n",
    "    testNonZeroIdx = np.nonzero(testMasks)\n",
    "    trainImages, trainLabels, trainMasks = loadData(inputDir,city)\n",
    "    trainNonZeroIdx = np.nonzero(testMasks)\n",
    "    print(testImages.shape)\n",
    "    trainimages = []\n",
    "    trainlables = []\n",
    "    for i in range(trainMasks.shape[0]):\n",
    "        for j in range(trainMasks.shape[1]):\n",
    "            if not np.all(trainMasks[i,j,:,:,0]== False):\n",
    "                trainlables.append(trainLabels[i,j,:,:,:])\n",
    "                trainimages.append(trainImages[i,j,:,:,:])\n",
    "\n",
    "    testimages = []\n",
    "    testlables = []\n",
    "    for i in range(testMasks.shape[0]):\n",
    "        for j in range(testMasks.shape[1]):\n",
    "            if not np.all(testMasks[i,j,:,:,0]== False):\n",
    "                testlables.append(testLabels[i,j,:,:,:])\n",
    "                testimages.append(testImages[i,j,:,:,:])\n",
    "    print(\"trainimages.shape\",np.array(trainimages).shape)\n",
    "   \n",
    "#     X = np.ndarray((np.array(trainimages).shape[0], rows_standard, cols_standard, channel_num), dtype=np.float32)\n",
    "#     y = np.ndarray((np.array(trainimages).shape[0], rows_standard, cols_standard, 1), dtype=np.float32)\n",
    "   \n",
    "#     Xtest = np.ndarray((np.array(testimages).shape[0], rows_standard, cols_standard, channel_num), dtype=np.float32)\n",
    "#     ytest = np.ndarray((np.array(testimages).shape[0], rows_standard, cols_standard, 1), dtype=np.float32)\n",
    "    \n",
    "#     if city == \"Utrecht\":\n",
    "#         X = np.asarray(trainimages)\n",
    "#         y = np.asarray(trainlables).astype(int)\n",
    "#         y[y >1] = 0\n",
    "#         Xtest = np.asarray(testimages)\n",
    "#         ytest =  np.asarray(testlables).astype(int)\n",
    "#         ytest[ytest >1] = 0\n",
    "#         print(city)\n",
    "#         print(\"X.shape\",X.shape, X.min(), X.max())\n",
    "#     else:\n",
    "    FLAIR_image = FLAIR_image[:, (image_rows_Dataset/2-rows_standard/2):(image_rows_Dataset/2+rows_standard/2), (image_cols_Dataset/2-cols_standard/2):(image_cols_Dataset/2+cols_standard/2)]\n",
    "\n",
    "    print(X.shape,np.asarray(trainimages).shape)\n",
    "    X = np.concatenate([X,np.asarray(trainimages)])\n",
    "    y = np.concatenate([y,np.asarray(trainlables).astype(int)])\n",
    "    y[y >1] = 0\n",
    "    print(X.shape, X.min(), X.max()) # (240, 240, 4) -0.380588 2.62761\n",
    "    print(y.shape, y.min(), y.max()) # (240, 240, 1) 0 1 \n",
    "\n",
    "    Xtest = np.concatenate([Xtest,np.asarray(testimages)])\n",
    "    ytest =  np.concatenate([ytest,np.asarray(testlables).astype(int)])\n",
    "    ytest[ytest >1] = 0\n",
    "    print(Xtest.shape, Xtest.min(), Xtest.max()) # (240, 240, 4) -0.380588 2.62761\n",
    "    print(ytest.shape, ytest.min(), ytest.max()) # (240, 240, 1) 0 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainimages = []\n",
    "trainlables = []\n",
    "for i in range(trainMasks.shape[0]):\n",
    "    for j in range(trainMasks.shape[1]):\n",
    "        if not np.all(trainMasks[i,j,:,:,0]== False):\n",
    "            trainlables.append(trainLabels[i,j,:,:,:])\n",
    "            trainimages.append(trainImages[i,j,:,:,:])\n",
    "\n",
    "testimages = []\n",
    "testlables = []\n",
    "for i in range(testMasks.shape[0]):\n",
    "    for j in range(testMasks.shape[1]):\n",
    "        if not np.all(testMasks[i,j,:,:,0]== False):\n",
    "            testlables.append(testLabels[i,j,:,:,:])\n",
    "            testimages.append(testImages[i,j,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(trainimages)\n",
    "y = np.asarray(trainlables).astype(int)\n",
    "y[y >1] = 0\n",
    "print(X.shape, X.min(), X.max()) # (240, 240, 4) -0.380588 2.62761\n",
    "print(y.shape, y.min(), y.max()) # (240, 240, 1) 0 1 \n",
    "\n",
    "Xtest = np.asarray(testimages)\n",
    "ytest = np.asarray(testlables).astype(int)\n",
    "ytest[ytest >1] = 0\n",
    "print(Xtest.shape, Xtest.min(), Xtest.max()) # (240, 240, 4) -0.380588 2.62761\n",
    "print(ytest.shape, ytest.min(), ytest.max()) # (240, 240, 1) 0 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def shuffle_list(*ls):\n",
    "    l =list(zip(*ls))\n",
    "    shuffle(l)\n",
    "    return zip(*l)\n",
    "\n",
    "Xs,ys = shuffle_list(X,y)\n",
    "Xs= np.array(Xs)\n",
    "ys= np.array(ys)\n",
    "print(Xs.shape)\n",
    "print(ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose,ZeroPadding2D, Dropout,UpSampling2D,Activation, Cropping2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_for_training(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.-dice_coef_for_training(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_relu(nd, k=3, inputs=None):\n",
    "    conv = Conv2D(nd, k, padding='same')(inputs) #, kernel_initializer='he_normal'\n",
    "    #bn = BatchNormalization()(conv)\n",
    "    relu = Activation('relu')(conv)\n",
    "    return relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_shape(target, refer):\n",
    "        # width, the 3rd dimension\n",
    "        cw = (target.get_shape()[2] - refer.get_shape()[2]).value\n",
    "        assert (cw >= 0)\n",
    "        if cw % 2 != 0:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "        else:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2)\n",
    "        # height, the 2nd dimension\n",
    "        ch = (target.get_shape()[1] - refer.get_shape()[1]).value\n",
    "        assert (ch >= 0)\n",
    "        if ch % 2 != 0:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "        else:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "        return (ch1, ch2), (cw1, cw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet():\n",
    "#     inputs = Input(batchShape[1:])\n",
    "#     conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "#     conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "#     conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "#     conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "#     conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "#     conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "#     conv4 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "#     conv4 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "#     drop4 = Dropout(0.5)(conv4)\n",
    "#     pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "#     conv5 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "#     conv5 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "#     drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "#     up6 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "#     merge6 = concatenate([drop4,up6], axis = -1)\n",
    "#     conv6 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "#     conv6 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "#     up7 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "#     merge7 = concatenate([conv3,up7], axis = -1)\n",
    "#     conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "#     conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "#     up8 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "#     merge8 = concatenate([conv2,up8], axis = -1)\n",
    "#     conv8 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "#     conv8 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "#     up9 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "#     merge9 = concatenate([conv1,up9], axis = -1)\n",
    "#     conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "#     conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "#     conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "#     conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "\n",
    "#     model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "#     model.compile(optimizer = Adam(lr = 1e-4), loss=dice_coef_loss)\n",
    "\n",
    "#     model.summary()\n",
    "    concat_axis = -1\n",
    "    filters = 3\n",
    "    inputs = Input(batchShape[1:])    \n",
    "    conv1 = conv_bn_relu(64, filters, inputs)\n",
    "    conv1 = conv_bn_relu(64, filters, conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = conv_bn_relu(96, 3, pool1)\n",
    "    conv2 = conv_bn_relu(96, 3, conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = conv_bn_relu(128, 3, pool2)\n",
    "    conv3 = conv_bn_relu(128, 3, conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = conv_bn_relu(256, 3, pool3)\n",
    "    conv4 = conv_bn_relu(256, 4, conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = conv_bn_relu(512, 3, pool4)\n",
    "    conv5 = conv_bn_relu(512, 3, conv5)\n",
    "\n",
    "    up_conv5 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    ch, cw = get_crop_shape(conv4, up_conv5)\n",
    "    crop_conv4 = Cropping2D(cropping=(ch,cw))(conv4)\n",
    "    up6 = concatenate([up_conv5, crop_conv4], axis=concat_axis)\n",
    "    conv6 = conv_bn_relu(256, 3, up6)\n",
    "    conv6 = conv_bn_relu(256, 3, conv6)\n",
    "\n",
    "    up_conv6 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    ch, cw = get_crop_shape(conv3, up_conv6)\n",
    "    crop_conv3 = Cropping2D(cropping=(ch,cw))(conv3)\n",
    "    up7 = concatenate([up_conv6, crop_conv3], axis=concat_axis)\n",
    "    conv7 = conv_bn_relu(128, 3, up7)\n",
    "    conv7 = conv_bn_relu(128, 3, conv7)\n",
    "\n",
    "    up_conv7 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    ch, cw = get_crop_shape(conv2, up_conv7)\n",
    "    crop_conv2 = Cropping2D(cropping=(ch,cw))(conv2)\n",
    "    up8 = concatenate([up_conv7, crop_conv2], axis=concat_axis)\n",
    "    conv8 = conv_bn_relu(96, 3, up8)\n",
    "    conv8 = conv_bn_relu(96, 3, conv8)\n",
    "\n",
    "    up_conv8 = UpSampling2D(size=(2, 2))(conv8)\n",
    "    ch, cw = get_crop_shape(conv1, up_conv8)\n",
    "    crop_conv1 = Cropping2D(cropping=(ch,cw))(conv1)\n",
    "    up9 = concatenate([up_conv8, crop_conv1], axis=concat_axis)\n",
    "    conv9 = conv_bn_relu(64, 3, up9)\n",
    "    conv9 = conv_bn_relu(64, 3, conv9)\n",
    "\n",
    "    ch, cw = get_crop_shape(inputs, conv9)\n",
    "    conv9 = ZeroPadding2D(padding=(ch, cw))(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid', padding='same')(conv9) #, kernel_initializer='he_normal'\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    model.compile(optimizer=Adam(lr=(2e-4)), loss=dice_coef_loss)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X,y):\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-'*30)\n",
    "    imgs_train, imgs_mask_train = np.array(X), np.array(y)#load_train_data()\n",
    "#     myshow(sitk.GetImageFromArray(imgs_train[:,:,0]))\n",
    "#     myshow(sitk.GetImageFromArray(imgs_train[:,:,1]))\n",
    "#     myshow(sitk.GetImageFromArray(imgs_mask_train))\n",
    "#     print(\"shape before\",imgs_train.shape,imgs_mask_train.shape)\n",
    "#     myshow(sitk.GetImageFromArray(imgs_train))\n",
    "\n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    "#     print(\"shapeagfter\",imgs_train.shape,imgs_mask_train.shape)\n",
    "#     myshow(sitk.GetImageFromArray(imgs_train))\n",
    "\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = get_unet()\n",
    "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "# #     myshow(sitk.GetImageFromArray(imgs_train))\n",
    "#     myshow(sitk.GetImageFromArray(imgs_mask_train))\n",
    "#     print(\"before model\",imgs_train.shape,imgs_mask_train.shape)\n",
    "    model.fit(imgs_train, imgs_mask_train, batch_size=20, nb_epoch=1, verbose=1, shuffle=True,\n",
    "              validation_split=0.2,\n",
    "              callbacks=[model_checkpoint])\n",
    "    \n",
    "    return model\n",
    "   \n",
    "def predict(model):    \n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-'*30)\n",
    "    testrange = range(len(ytest))\n",
    "    imgs_test, imgs_id_test = Xtest, ytest\n",
    "#     print(\"before test pre\",imgs_test.shape,imgs_id_test)\n",
    "    imgs_test = preprocess(imgs_test)\n",
    "#     print(\"after test pre\",imgs_test.shape,imgs_id_test)\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    mean = np.mean(imgs_test)  # mean for data centering\n",
    "    std = np.std(imgs_test)  # std for data normalization\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-'*30)\n",
    "    model.load_weights('weights.h5')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-'*30)\n",
    "#     print(\"test model\",imgs_test.shape)\n",
    "    imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "    print(\"test model finished\",imgs_mask_test.shape)\n",
    "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "    myshow(sitk.GetImageFromArray(imgs_test[50,:,:,1]))\n",
    "    myshow(sitk.GetImageFromArray(imgs_id_test[50,:,:,0]))\n",
    "    myshow(sitk.GetImageFromArray(imgs_mask_test[50,:,:,0]))\n",
    "    print('-' * 30)\n",
    "    print('Saving predicted masks to files...')\n",
    "    print('-' * 30)\n",
    "    pred_dir = 'preds'\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "    for image, image_id in zip(imgs_mask_test, testrange):\n",
    "#         print(image_id)\n",
    "        nn = 0\n",
    "#         print(image.shape)\n",
    "        image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "        imsave(os.path.join(pred_dir,str(image_id) + '_pred.png'), image)\n",
    "        nn+=1\n",
    "    print(imgs_id_test.shape,imgs_mask_test.shape)\n",
    "    return imgs_id_test,imgs_mask_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xchunks = [Xs[x:x+100] for x in range(0, len(Xs), 100)]\n",
    "ychunks = [ys[x:x+100] for x in range(0, len(ys), 100)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "#     for i,j in zip(Xchunks[-5:],ychunks[-5:]):\n",
    "#         model = train(i,j)\n",
    "    model = train(Xchunks[2],ychunks[2])\n",
    "    testFilename, resultFilename = predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
