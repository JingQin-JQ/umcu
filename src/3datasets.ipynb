{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codes for validating the WMH Challenge training Datasets. The algorithm won the WMH Challenge.\n",
    "#Codes are written by Mr. Hongwei Li (h.l.li@dundee.ac.uk), Mr. Gongfa Jiang and Miss. Zhaolei Wang from Sun Yat-sen University and University of Dundee.\n",
    "#\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "import difflib\n",
    "import SimpleITK as sitk\n",
    "import scipy.spatial\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Cropping2D, ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "# from evaluation import getDSC, getHausdorff, getLesionDetection, getAVD, getImages  #please download evaluation.py from the WMH website\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "# from show import imshow\n",
    "from scipy import ndimage\n",
    "#from sklearn.utils import class_weight\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "# import plotly.plotly as py\n",
    "# import plotly.figure_factory as ff\n",
    "# import plotly.graph_objs as go \n",
    "\n",
    "### ----define loss function for U-net ------------\n",
    "smooth = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Utrecht_preprocessing(FLAIR_image, T1_image,labelArray):\n",
    "\n",
    "    channel_num = 2\n",
    "    print(np.shape(FLAIR_image))\n",
    "    num_selected_slice = np.shape(FLAIR_image)[0]\n",
    "    image_rows_Dataset = np.shape(FLAIR_image)[1]\n",
    "    image_cols_Dataset = np.shape(FLAIR_image)[2]\n",
    "    T1_image = np.float32(T1_image)\n",
    "\n",
    "    brain_mask_FLAIR = np.ndarray((np.shape(FLAIR_image)[0],image_rows_Dataset, image_cols_Dataset), dtype=np.float32)\n",
    "    brain_mask_T1 = np.ndarray((np.shape(FLAIR_image)[0],image_rows_Dataset, image_cols_Dataset), dtype=np.float32)\n",
    "    imgs_two_channels = np.ndarray((num_selected_slice, rows_standard, cols_standard, channel_num), dtype=np.float32)\n",
    "    brain_label = np.ndarray((np.shape(FLAIR_image)[0],image_rows_Dataset, image_cols_Dataset), dtype=np.float32)\n",
    "    imgs_mask_two_channels = np.ndarray((num_selected_slice, rows_standard, cols_standard,1), dtype=np.float32)\n",
    "\n",
    "    # FLAIR --------------------------------------------\n",
    "    brain_mask_FLAIR[FLAIR_image >=thresh_FLAIR] = 1\n",
    "    brain_mask_FLAIR[FLAIR_image < thresh_FLAIR] = 0\n",
    "    for iii in range(np.shape(FLAIR_image)[0]):\n",
    "        brain_mask_FLAIR[iii,:,:] = scipy.ndimage.morphology.binary_fill_holes(brain_mask_FLAIR[iii,:,:])  #fill the holes inside brain\n",
    "    print(int(image_rows_Dataset/2-rows_standard/2),int(image_rows_Dataset/2+rows_standard/2), int(image_cols_Dataset/2-cols_standard/2),int(image_cols_Dataset/2+cols_standard/2))\n",
    "    print(FLAIR_image.shape)\n",
    "    \n",
    "    FLAIR_image = FLAIR_image[:, int(image_rows_Dataset/2-rows_standard/2):int(image_rows_Dataset/2+rows_standard/2), int(image_cols_Dataset/2-cols_standard/2):int(image_cols_Dataset/2+cols_standard/2)]\n",
    "    brain_mask_FLAIR = brain_mask_FLAIR[:, int(image_rows_Dataset/2-rows_standard/2):int(image_rows_Dataset/2+rows_standard/2), int(image_cols_Dataset/2-cols_standard/2):int(image_cols_Dataset/2+cols_standard/2)]\n",
    "    ###------Gaussion Normalization here\n",
    "    FLAIR_image -=np.mean(FLAIR_image[brain_mask_FLAIR == 1])      #Gaussion Normalization\n",
    "    FLAIR_image /=np.std(FLAIR_image[brain_mask_FLAIR == 1])\n",
    "    # T1 -----------------------------------------------\n",
    "    brain_mask_T1[T1_image >=thresh_T1] = 1\n",
    "    brain_mask_T1[T1_image < thresh_T1] = 0\n",
    "    for iii in range(np.shape(T1_image)[0]):\n",
    "        brain_mask_T1[iii,:,:] = scipy.ndimage.morphology.binary_fill_holes(brain_mask_T1[iii,:,:])  #fill the holes inside brain\n",
    "    T1_image = T1_image[:, int(image_rows_Dataset/2-rows_standard/2):int(image_rows_Dataset/2+rows_standard/2), int(image_cols_Dataset/2-cols_standard/2):int(image_cols_Dataset/2+cols_standard/2)]\n",
    "    brain_mask_T1 = brain_mask_T1[:, int(image_rows_Dataset/2-rows_standard/2):int(image_rows_Dataset/2+rows_standard/2), int(image_cols_Dataset/2-cols_standard/2):int(image_cols_Dataset/2+cols_standard/2)]\n",
    "    #------Gaussion Normalization\n",
    "    T1_image -=np.mean(T1_image[brain_mask_T1 == 1])      \n",
    "    T1_image /=np.std(T1_image[brain_mask_T1 == 1])\n",
    "    # lable----------------\n",
    "    brain_label[labelArray == 1] = 1\n",
    "    brain_label[labelArray != 1] = 0\n",
    "    imgs_mask_two_channels = brain_label[:, int(image_rows_Dataset/2-rows_standard/2):int(image_rows_Dataset/2+rows_standard/2), int(image_cols_Dataset/2-cols_standard/2):int(image_cols_Dataset/2+cols_standard/2)]\n",
    "    #---------------------------------------------------\n",
    "    FLAIR_image  = FLAIR_image[..., np.newaxis]\n",
    "    T1_image  = T1_image[..., np.newaxis]\n",
    "    imgs_two_channels = np.concatenate((FLAIR_image, T1_image), axis = 3)\n",
    "    print(np.shape(imgs_mask_two_channels))\n",
    "    print(np.shape(imgs_two_channels))\n",
    "    maskArray = imgs_mask_two_channels > 0\n",
    "\n",
    "    return imgs_two_channels,imgs_mask_two_channels, maskArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Utrecht_postprocessing(FLAIR_array, pred):\n",
    "    start_slice = 6\n",
    "    num_selected_slice = np.shape(FLAIR_array)[0]\n",
    "    image_rows_Dataset = np.shape(FLAIR_array)[1]\n",
    "    image_cols_Dataset = np.shape(FLAIR_array)[2]\n",
    "    original_pred = np.ndarray(np.shape(FLAIR_array), dtype=np.float32)\n",
    "    original_pred[:,(image_rows_Dataset-rows_standard)/2:(image_rows_Dataset+rows_standard)/2,(image_cols_Dataset-cols_standard)/2:(image_cols_Dataset+cols_standard)/2] = pred[:,:,:,0]\n",
    "    \n",
    "    original_pred[0:start_slice, :, :] = 0\n",
    "    original_pred[(num_selected_slice-start_slice-1):(num_selected_slice-1), :, :] = 0\n",
    "    return original_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GE3T_preprocessing(FLAIR_image, T1_image,labelArray):\n",
    "\n",
    "  #  start_slice = 10\n",
    "    channel_num = 2\n",
    "    start_cut = 46\n",
    "    print(np.shape(FLAIR_image))\n",
    "    num_selected_slice = np.shape(FLAIR_image)[0]\n",
    "    image_rows_Dataset = np.shape(FLAIR_image)[1]\n",
    "    image_cols_Dataset = np.shape(FLAIR_image)[2]\n",
    "    FLAIR_image = np.float32(FLAIR_image)\n",
    "    T1_image = np.float32(T1_image)\n",
    "\n",
    "    brain_mask_FLAIR = np.ndarray((np.shape(FLAIR_image)[0],image_rows_Dataset, image_cols_Dataset), dtype=np.float32)\n",
    "    brain_mask_T1 = np.ndarray((np.shape(FLAIR_image)[0],image_rows_Dataset, image_cols_Dataset), dtype=np.float32)\n",
    "    imgs_two_channels = np.ndarray((num_selected_slice, rows_standard, cols_standard, channel_num), dtype=np.float32)\n",
    "    \n",
    "    FLAIR_image_suitable = np.ndarray((num_selected_slice, rows_standard, cols_standard), dtype=np.float32)\n",
    "    T1_image_suitable = np.ndarray((num_selected_slice, rows_standard, cols_standard), dtype=np.float32)\n",
    "    brain_label = np.ndarray((np.shape(FLAIR_image)[0],image_rows_Dataset, image_cols_Dataset), dtype=np.float32)\n",
    "    imgs_mask_two_channels = np.ndarray((num_selected_slice, rows_standard, cols_standard), dtype=np.float32)\n",
    "\n",
    "    # FLAIR --------------------------------------------\n",
    "    brain_mask_FLAIR[FLAIR_image >=thresh_FLAIR] = 1\n",
    "    brain_mask_FLAIR[FLAIR_image < thresh_FLAIR] = 0\n",
    "    for iii in range(np.shape(FLAIR_image)[0]):\n",
    "  \n",
    "        brain_mask_FLAIR[iii,:,:] = scipy.ndimage.morphology.binary_fill_holes(brain_mask_FLAIR[iii,:,:])  #fill the holes inside brain\n",
    "        #------Gaussion Normalization\n",
    "    FLAIR_image -=np.mean(FLAIR_image[brain_mask_FLAIR == 1])      #Gaussion Normalization\n",
    "    FLAIR_image /=np.std(FLAIR_image[brain_mask_FLAIR == 1])\n",
    "\n",
    "    FLAIR_image_suitable[...] = np.min(FLAIR_image)\n",
    "    FLAIR_image_suitable[:, :, int(cols_standard/2-image_cols_Dataset/2):int(cols_standard/2+image_cols_Dataset/2)] = FLAIR_image[:, start_cut:start_cut+rows_standard, :]\n",
    "   \n",
    "    # T1 -----------------------------------------------\n",
    "    brain_mask_T1[T1_image >=thresh_T1] = 1\n",
    "    brain_mask_T1[T1_image < thresh_T1] = 0\n",
    "    for iii in range(np.shape(T1_image)[0]):\n",
    " \n",
    "        brain_mask_T1[iii,:,:] = scipy.ndimage.morphology.binary_fill_holes(brain_mask_T1[iii,:,:])  #fill the holes inside brain\n",
    "        #------Gaussion Normalization\n",
    "    T1_image -=np.mean(T1_image[brain_mask_T1 == 1])      #Gaussion Normalization\n",
    "    T1_image /=np.std(T1_image[brain_mask_T1 == 1])\n",
    "\n",
    "    T1_image_suitable[...] = np.min(T1_image)\n",
    "    T1_image_suitable[:, :, int((cols_standard-image_cols_Dataset)/2):int((cols_standard+image_cols_Dataset)/2)] = T1_image[:, start_cut:start_cut+rows_standard, :]\n",
    "    # lable----------------\n",
    "    brain_label[labelArray == 1] = 1\n",
    "    brain_label[labelArray != 1] = 0\n",
    "    imgs_mask_two_channels[:, :, int((cols_standard-image_cols_Dataset)/2):int((cols_standard+image_cols_Dataset)/2)] = brain_label[:, start_cut:start_cut+rows_standard, :]\n",
    "    \n",
    "    #---------------------------------------------------\n",
    "    FLAIR_image_suitable  = FLAIR_image_suitable[..., np.newaxis]\n",
    "    T1_image_suitable  = T1_image_suitable[..., np.newaxis]\n",
    "    \n",
    "    imgs_two_channels = np.concatenate((FLAIR_image_suitable, T1_image_suitable), axis = 3)\n",
    "    maskArray = imgs_mask_two_channels > 0\n",
    "    print(np.shape(imgs_two_channels))\n",
    "    return imgs_two_channels,imgs_mask_two_channels,maskArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(3/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GE3T_postprocessing(FLAIR_array, pred):\n",
    "    start_slice = 11\n",
    "    start_cut = 46\n",
    "    num_selected_slice = np.shape(FLAIR_array)[0]\n",
    "    image_rows_Dataset = np.shape(FLAIR_array)[1]\n",
    "    image_cols_Dataset = np.shape(FLAIR_array)[2]\n",
    "    original_pred = np.ndarray(np.shape(FLAIR_array), dtype=np.float32)\n",
    "    original_pred[:, start_cut:start_cut+rows_standard,:] = pred[:,:, (rows_standard-image_cols_Dataset)/2:(rows_standard+image_cols_Dataset)/2,0]\n",
    "\n",
    "    original_pred[0:start_slice, :, :] = 0\n",
    "    original_pred[(num_selected_slice-start_slice-1):(num_selected_slice-1), :, :] = 0\n",
    "    return original_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21', '23', '31', '35', '50', '55', '56', '60', '62', '100', '105', '106', '110', '113']\n",
      "dir_name is:\n",
      "21\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2) (48, 200, 200) (48, 200, 200)\n",
      "hehe (1, 48, 200, 200, 2) (1, 48, 200, 200, 1) (1, 48, 200, 200, 1) 5.7240167\n",
      "max: 4.362728\n",
      "max: 5.1427183\n",
      "max: 4.776386\n",
      "max: 4.3169985\n",
      "max: 4.740326\n",
      "max: 4.793553\n",
      "max: 5.0530953\n",
      "max: 4.8989935\n",
      "max: 4.3028836\n",
      "max: 4.4358244\n",
      "max: 4.3551927\n",
      "max: 4.3547955\n",
      "max: 4.3620734\n",
      "max: 4.6707845\n",
      "max: 4.6877866\n",
      "max: 4.1151795\n",
      "max: 4.7104096\n",
      "max: 4.3052025\n",
      "max: 4.801093\n",
      "max: 4.496967\n",
      "max: 4.9930186\n",
      "max: 4.4287314\n",
      "max: 4.4444366\n",
      "max: 4.2412643\n",
      "max: 4.12495\n",
      "max: 3.9727085\n",
      "max: 3.7560663\n",
      "max: 3.6715212\n",
      "max: 3.9394782\n",
      "max: 3.9315321\n",
      "max: 3.4742377\n",
      "max: 3.4050465\n",
      "max: 4.097337\n",
      "max: 3.7792242\n",
      "t: (34, 200, 200, 1) (34, 200, 200, 2) 5.1427183\n",
      "dir_name is:\n",
      "23\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2) (48, 200, 200) (48, 200, 200)\n",
      "hehe (1, 48, 200, 200, 2) (1, 48, 200, 200, 1) (1, 48, 200, 200, 1) 5.308387\n",
      "max: 4.7807465\n",
      "max: 4.5867424\n",
      "max: 4.408907\n",
      "max: 4.76798\n",
      "max: 4.841464\n",
      "max: 4.8639917\n",
      "max: 5.091249\n",
      "max: 4.3367577\n",
      "max: 4.3203225\n",
      "max: 4.244796\n",
      "max: 4.3882604\n",
      "max: 4.413569\n",
      "max: 4.354054\n",
      "max: 4.6515694\n",
      "max: 4.27785\n",
      "max: 4.134882\n",
      "max: 4.192518\n",
      "max: 4.2957835\n",
      "t: (52, 200, 200, 1) (52, 200, 200, 2) 5.1427183\n",
      "dir_name is:\n",
      "31\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2) (48, 200, 200) (48, 200, 200)\n",
      "hehe (1, 48, 200, 200, 2) (1, 48, 200, 200, 1) (1, 48, 200, 200, 1) 5.2552934\n",
      "max: 3.5758567\n",
      "max: 4.9563155\n",
      "max: 4.966979\n",
      "max: 4.6655717\n",
      "max: 4.737205\n",
      "max: 3.8229852\n",
      "max: 4.043338\n",
      "max: 3.4852986\n",
      "max: 3.5634646\n",
      "max: 3.8556445\n",
      "max: 3.9603093\n",
      "max: 3.769443\n",
      "max: 3.5907102\n",
      "max: 4.1762443\n",
      "max: 4.0889263\n",
      "max: 4.065653\n",
      "max: 3.7803273\n",
      "max: 3.7964146\n",
      "max: 3.594109\n",
      "max: 3.8258348\n",
      "max: 4.3889675\n",
      "max: 3.9645112\n",
      "max: 3.467739\n",
      "max: 3.6189055\n",
      "max: 3.694777\n",
      "max: 3.4823906\n",
      "max: 3.567765\n",
      "t: (79, 200, 200, 1) (79, 200, 200, 2) 5.1427183\n",
      "dir_name is:\n",
      "35\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2) (48, 200, 200) (48, 200, 200)\n",
      "hehe (1, 48, 200, 200, 2) (1, 48, 200, 200, 1) (1, 48, 200, 200, 1) 6.8676205\n",
      "max: 5.401128\n",
      "max: 5.5446587\n",
      "max: 5.663831\n",
      "max: 5.0441446\n",
      "max: 5.0505953\n",
      "max: 5.1592894\n",
      "max: 5.2637954\n",
      "max: 5.1245112\n",
      "max: 6.3603516\n",
      "max: 6.48675\n",
      "max: 6.100231\n",
      "max: 4.9949183\n",
      "max: 4.7243133\n",
      "max: 4.6865587\n",
      "max: 4.4502473\n",
      "max: 4.7253976\n",
      "max: 4.6655197\n",
      "max: 4.457613\n",
      "max: 4.4615216\n",
      "max: 4.097938\n",
      "max: 4.0369587\n",
      "max: 3.9522333\n",
      "max: 3.8247895\n",
      "max: 3.776224\n",
      "t: (103, 200, 200, 1) (103, 200, 200, 2) 6.48675\n",
      "dir_name is:\n",
      "50\n",
      "From Singapore!\n",
      "(48, 232, 256)\n",
      "16 216 28 228\n",
      "(48, 232, 256)\n",
      "(48, 200, 200)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2) (48, 200, 200) (48, 200, 200)\n",
      "hehe (1, 48, 200, 200, 2) (1, 48, 200, 200, 1) (1, 48, 200, 200, 1) 7.6521597\n",
      "max: 4.370046\n",
      "max: 3.5152466\n",
      "max: 2.9007382\n",
      "max: 3.0473232\n",
      "max: 3.4303207\n",
      "max: 3.3833423\n",
      "max: 3.283166\n",
      "max: 3.3285763\n",
      "max: 3.4551582\n",
      "max: 3.3764346\n",
      "max: 3.1708078\n",
      "max: 3.1888459\n",
      "max: 3.2396905\n",
      "max: 2.8914945\n",
      "max: 2.7860327\n",
      "max: 2.6775968\n",
      "max: 2.755106\n",
      "max: 2.946038\n",
      "max: 2.6243665\n",
      "max: 2.2619958\n",
      "max: 2.5426247\n",
      "max: 2.2770765\n",
      "max: 2.1726625\n",
      "t: (126, 200, 200, 1) (126, 200, 200, 2) 6.48675\n",
      "dir_name is:\n",
      "55\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2) (48, 200, 200) (48, 200, 200)\n",
      "hehe (1, 48, 200, 200, 2) (1, 48, 200, 200, 1) (1, 48, 200, 200, 1) 13.058325\n",
      "max: 3.7062879\n",
      "max: 4.013986\n",
      "max: 6.8010206\n",
      "max: 4.2428226\n",
      "max: 3.5636127\n",
      "max: 6.705787\n",
      "max: 4.2373714\n",
      "max: 3.544118\n",
      "max: 4.453611\n",
      "max: 5.8655434\n",
      "max: 5.311144\n",
      "max: 6.1922426\n",
      "max: 4.360745\n",
      "max: 4.182545\n",
      "max: 4.162745\n",
      "max: 4.2815447\n",
      "max: 4.063745\n",
      "max: 4.212245\n",
      "max: 4.063745\n",
      "max: 4.113245\n",
      "t: (146, 200, 200, 1) (146, 200, 200, 2) 6.8010206\n",
      "dir_name is:\n",
      "56\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2) (48, 200, 200) (48, 200, 200)\n",
      "hehe (1, 48, 200, 200, 2) (1, 48, 200, 200, 1) (1, 48, 200, 200, 1) 8.535157\n",
      "max: 4.550908\n",
      "max: 4.09541\n",
      "max: 3.3965628\n",
      "max: 3.127097\n",
      "max: 3.3590841\n",
      "max: 3.311827\n",
      "max: 3.4706073\n",
      "max: 3.520473\n",
      "max: 3.0920525\n",
      "max: 3.3730912\n",
      "max: 3.307588\n",
      "max: 3.0321736\n",
      "max: 3.096961\n",
      "max: 2.7811747\n",
      "max: 2.5524533\n",
      "max: 2.8070335\n",
      "max: 2.6542854\n",
      "t: (163, 200, 200, 1) (163, 200, 200, 2) 6.8010206\n",
      "dir_name is:\n",
      "60\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2) (48, 200, 200) (48, 200, 200)\n",
      "hehe (1, 48, 200, 200, 2) (1, 48, 200, 200, 1) (1, 48, 200, 200, 1) 9.5108385\n",
      "max: 5.503763\n",
      "max: 3.8746786\n",
      "max: 4.379638\n",
      "max: 3.6857338\n",
      "max: 3.4220502\n",
      "max: 3.442461\n",
      "max: 3.7130082\n",
      "max: 3.4596245\n",
      "max: 4.4416\n",
      "max: 3.7690024\n",
      "max: 3.9632957\n",
      "max: 3.6024654\n",
      "max: 3.3692305\n",
      "max: 3.5747092\n",
      "max: 3.546953\n",
      "max: 3.6302216\n",
      "max: 3.6302216\n",
      "max: 3.241635\n",
      "max: 3.2555132\n",
      "t: (182, 200, 200, 1) (182, 200, 200, 2) 6.8010206\n",
      "dir_name is:\n",
      "62\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2) (48, 200, 200) (48, 200, 200)\n",
      "hehe (1, 48, 200, 200, 2) (1, 48, 200, 200, 1) (1, 48, 200, 200, 1) 10.106113\n",
      "max: 6.6209736\n",
      "max: 5.9625735\n",
      "max: 4.098183\n",
      "max: 3.7062924\n",
      "max: 3.453421\n",
      "max: 3.8738573\n",
      "max: 4.691181\n",
      "max: 3.885209\n",
      "max: 3.8170986\n",
      "max: 3.4878986\n",
      "max: 3.5393255\n",
      "max: 3.930616\n",
      "max: 4.713885\n",
      "max: 3.2495124\n",
      "max: 3.1814356\n",
      "max: 3.1651142\n",
      "max: 4.08954\n",
      "max: 4.577664\n",
      "max: 3.5333056\n",
      "max: 3.1814022\n",
      "max: 2.9650722\n",
      "max: 2.8834922\n",
      "max: 2.6024644\n",
      "max: 2.5116506\n",
      "max: 2.4266596\n",
      "max: 2.4745603\n",
      "max: 3.0580497\n",
      "max: 2.0180748\n",
      "t: (210, 200, 200, 1) (210, 200, 200, 2) 6.8010206\n",
      "dir_name is:\n",
      "100\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2) (83, 200, 200) (83, 200, 200)\n",
      "hehe (1, 83, 200, 200, 2) (1, 83, 200, 200, 1) (1, 83, 200, 200, 1) 5.171447\n",
      "max: 4.757814\n",
      "max: 4.894209\n",
      "max: 4.5235705\n",
      "max: 5.0483947\n",
      "max: 5.116592\n",
      "max: 4.640692\n",
      "max: 4.654035\n",
      "max: 5.12697\n",
      "max: 4.6451397\n",
      "max: 4.514675\n",
      "max: 4.694064\n",
      "max: 4.7563314\n",
      "max: 4.6125236\n",
      "max: 4.8897614\n",
      "max: 4.7889476\n",
      "max: 4.557669\n",
      "max: 4.5561867\n",
      "max: 4.5532217\n",
      "max: 4.6125236\n",
      "max: 4.321943\n",
      "max: 4.4509254\n",
      "max: 4.6599655\n",
      "max: 4.573977\n",
      "max: 4.628832\n",
      "max: 4.5962157\n",
      "t: (235, 200, 200, 1) (235, 200, 200, 2) 6.8010206\n",
      "dir_name is:\n",
      "105\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2) (83, 200, 200) (83, 200, 200)\n",
      "hehe (1, 83, 200, 200, 2) (1, 83, 200, 200, 1) (1, 83, 200, 200, 1) 7.6534824\n",
      "max: 4.5557833\n",
      "max: 4.7264266\n",
      "max: 4.826082\n",
      "max: 4.8701863\n",
      "max: 5.0858827\n",
      "max: 4.9657865\n",
      "max: 4.836305\n",
      "max: 4.512099\n",
      "max: 4.614485\n",
      "max: 4.378327\n",
      "max: 5.3956017\n",
      "max: 4.776937\n",
      "max: 4.628136\n",
      "max: 4.8738623\n",
      "max: 4.8192563\n",
      "max: 4.8015094\n",
      "max: 4.8383684\n",
      "max: 4.9038954\n",
      "max: 5.059522\n",
      "max: 4.787858\n",
      "max: 5.236991\n",
      "max: 5.0731735\n",
      "max: 5.160543\n",
      "t: (258, 200, 200, 1) (258, 200, 200, 2) 6.8010206\n",
      "dir_name is:\n",
      "106\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2) (83, 200, 200) (83, 200, 200)\n",
      "hehe (1, 83, 200, 200, 2) (1, 83, 200, 200, 1) (1, 83, 200, 200, 1) 4.8775706\n",
      "max: 4.870553\n",
      "max: 4.8775706\n",
      "max: 4.7021255\n",
      "max: 4.6698437\n",
      "max: 4.363867\n",
      "max: 4.386324\n",
      "max: 4.5603657\n",
      "max: 4.6606984\n",
      "max: 4.680732\n",
      "max: 4.507007\n",
      "max: 4.3554454\n",
      "max: 4.44387\n",
      "max: 4.6923003\n",
      "max: 4.763882\n",
      "max: 4.744232\n",
      "t: (273, 200, 200, 1) (273, 200, 200, 2) 6.8010206\n",
      "dir_name is:\n",
      "110\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2) (83, 200, 200) (83, 200, 200)\n",
      "hehe (1, 83, 200, 200, 2) (1, 83, 200, 200, 1) (1, 83, 200, 200, 1) 5.701298\n",
      "max: 4.315636\n",
      "max: 5.0021443\n",
      "max: 4.3192496\n",
      "max: 4.294357\n",
      "max: 4.676956\n",
      "max: 4.004901\n",
      "max: 4.010321\n",
      "max: 4.2379527\n",
      "max: 4.2740846\n",
      "max: 4.2560186\n",
      "max: 4.019354\n",
      "max: 4.2885375\n",
      "max: 5.070795\n",
      "max: 5.464634\n",
      "max: 5.0021443\n",
      "max: 4.7185082\n",
      "max: 4.9678187\n",
      "max: 4.9334936\n",
      "max: 5.4556007\n",
      "max: 5.56761\n",
      "max: 5.3255258\n",
      "max: 5.701298\n",
      "t: (295, 200, 200, 1) (295, 200, 200, 2) 6.8010206\n",
      "dir_name is:\n",
      "113\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2) (83, 200, 200) (83, 200, 200)\n",
      "hehe (1, 83, 200, 200, 2) (1, 83, 200, 200, 1) (1, 83, 200, 200, 1) 9.251886\n",
      "max: 4.216688\n",
      "max: 4.566494\n",
      "max: 4.294744\n",
      "max: 4.5404754\n",
      "max: 4.8859444\n",
      "max: 5.40198\n",
      "max: 6.0336537\n",
      "max: 6.0582266\n",
      "max: 6.3588862\n",
      "max: 6.8966036\n",
      "max: 6.7231464\n",
      "max: 6.412369\n",
      "max: 7.7884636\n",
      "max: 7.0599427\n",
      "max: 7.239182\n",
      "max: 6.5323434\n",
      "max: 6.870585\n",
      "max: 7.4025207\n",
      "max: 6.922622\n",
      "max: 6.483197\n",
      "max: 6.380568\n",
      "max: 6.606063\n",
      "max: 6.6421995\n",
      "max: 5.87176\n",
      "max: 5.06952\n",
      "max: 5.147576\n",
      "max: 4.8917265\n",
      "max: 5.1866035\n",
      "max: 4.818007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: (324, 200, 200, 1) (324, 200, 200, 2) 7.7884636\n",
      "(1, 83, 200, 200, 2) (1, 83, 200, 200, 1) (1, 83, 200, 200, 1)\n",
      "(324, 200, 200, 1) (324, 200, 200, 2)\n"
     ]
    }
   ],
   "source": [
    "###---Here comes the main funtion--------------------------------------------\n",
    "###---Leave one patient out validation--------------------------------------------\n",
    "\n",
    "patient_num =45\n",
    "patient_count = 0\n",
    "rows_standard = 200\n",
    "cols_standard = 200\n",
    "thresh_FLAIR = 70      #to mask the brain\n",
    "thresh_T1 = 30\n",
    "para_array = [[0.958, 0.958, 3], [1.00, 1.00, 3], [1.20, 0.977, 3]]    # parameters of the scanner\n",
    "para_array = np.array(para_array, dtype=np.float32)\n",
    "\n",
    "images = None # shape: (numImages, z, y, x, channels=1)\n",
    "labels = None\n",
    "masks  = None\n",
    "\n",
    "validationimages = []\n",
    "validationlables = []\n",
    "\n",
    "#read the dirs of test data \n",
    "input_dir_1 = '../data/validation/Utrecht'\n",
    "input_dir_2 = '../data/validation/Singapore'\n",
    "input_dir_3 = '../data/validation/Amsterdam'\n",
    "###---dir to save results---------\n",
    "outputDir = 'evaluation_result_LOOV'\n",
    "  \n",
    "#-------------------------------------------   \n",
    "dirs = os.listdir(input_dir_1) + os.listdir(input_dir_2) + os.listdir(input_dir_3)\n",
    "# #All the slices and the corresponding patients id\n",
    "# imgs_three_datasets_two_channels = np.load('imgs_three_datasets_two_channels.npy')\n",
    "# imgs_mask_three_datasets_two_channels = np.load('imgs_mask_three_datasets_two_channels.npy')\n",
    "# slices_patient_id_label = np.load('slices_patient_id_label.npy')\n",
    "dirs = [f for f in dirs if not f.startswith('.')]\n",
    "print(dirs)\n",
    "for dir_name in dirs:\n",
    "    print('dir_name is:')\n",
    "    print(dir_name)\n",
    "    \n",
    "    if patient_count < 4:\n",
    "        inputDir = input_dir_1\n",
    "    elif patient_count > 3 and patient_count < 9:\n",
    "        inputDir = input_dir_2\n",
    "    elif patient_count >= 9:\n",
    "        inputDir = input_dir_3\n",
    "    FLAIR_image = sitk.ReadImage(os.path.join(inputDir, dir_name, 'pre', 'FLAIR.nii.gz'))\n",
    "    T1_image = sitk.ReadImage(os.path.join(inputDir, dir_name, 'pre', 'T1.nii.gz'))\n",
    "    label_image= sitk.ReadImage(os.path.join(inputDir, dir_name, \"wmh.nii.gz\"))\n",
    "    FLAIR_array = sitk.GetArrayFromImage(FLAIR_image)\n",
    "    T1_array = sitk.GetArrayFromImage(T1_image)\n",
    "    labelArray = sitk.GetArrayFromImage(label_image)\n",
    "    \n",
    "    #Proccess testing data-----\n",
    "    para_FLAIR = np.ndarray((1,3), dtype=np.float32)\n",
    "    para_FLAIR_ = FLAIR_image.GetSpacing()\n",
    "    para_FLAIR[0,0] = round(para_FLAIR_[0],3)   # get spacing parameters of the data\n",
    "    para_FLAIR[0,1] = round(para_FLAIR_[1],3)  \n",
    "    para_FLAIR[0,2] = round(para_FLAIR_[2],3) \n",
    "    if np.array_equal(para_FLAIR[0], para_array[0]) :\n",
    "        print('From Utrecht!')\n",
    "        imgs_test,label,maskArray = Utrecht_preprocessing(FLAIR_array, T1_array, labelArray)\n",
    "    elif np.array_equal(para_FLAIR[0], para_array[1]):\n",
    "        print('From Singapore!')\n",
    "        imgs_test,label,maskArray  = Utrecht_preprocessing(FLAIR_array, T1_array, labelArray)\n",
    "    elif np.array_equal(para_FLAIR[0], para_array[2]):\n",
    "        print('From Amsterdam!')\n",
    "        imgs_test,label,maskArray  = GE3T_preprocessing(FLAIR_array, T1_array, labelArray)\n",
    "    print(imgs_test.shape,label.shape,maskArray.shape)\n",
    "    patient_count+=1\n",
    "    \n",
    "           \n",
    "    # Add to the images/labels array\n",
    "    images = imgs_test.reshape([1] + list(imgs_test.shape) )\n",
    "    labels = label.reshape([1] + list(label.shape) + [1])\n",
    "    masks  = maskArray.reshape([1] + list(maskArray.shape) + [1])\n",
    "    print(\"hehe\",images.shape, labels.shape, masks.shape,images.max())\n",
    "    for i in range(masks.shape[0]):\n",
    "        for j in range(masks.shape[1]):\n",
    "            if not np.all(masks[i,j,:,:,0]== False):\n",
    "                validationlables.append(labels[i,j,:,:,:])\n",
    "#                 print(\"max:\",images[i,j,:,:,:].max())\n",
    "                validationimages.append(images[i,j,:,:,:])\n",
    "\n",
    "      \n",
    "    print(\"t:\", np.asarray(validationlables).shape,np.asarray(validationimages).shape,np.asarray(validationimages).max() )\n",
    "print(images.shape, labels.shape, masks.shape)   \n",
    "print(np.asarray(validationlables).shape,np.asarray(validationimages).shape)\n",
    "#     ###---train u-net models-------------------------------------------------------------------------------\n",
    "#     training_index = slices_patient_id_label != patient_count\n",
    "#     test_index = slices_patient_id_label == patient_count\n",
    "#     dim_training = sum(training_index)\n",
    "#     dim_test = sum(test_index)\n",
    "#     print('the dim of training set:')\n",
    "#     print(dim_training[0])\n",
    "#     imgs_train = np.ndarray((dim_training[0], rows_standard, cols_standard, 2), dtype=np.float32)\n",
    "#     imgs_test_selected = np.ndarray((dim_test[0], rows_standard, cols_standard, 2), dtype=np.float32)\n",
    "\n",
    "#     imgs_mask_train = np.ndarray((dim_training[0], rows_standard, cols_standard, 1), dtype=np.float32)\n",
    "#     imgs_mask_test_selected = np.ndarray((dim_test[0], rows_standard, cols_standard, 1), dtype=np.float32)\n",
    "#     count_index_train = 0\n",
    "#     count_index_test = 0\n",
    "#     for iii in range(training_index.shape[0]):\n",
    "#         if training_index[iii] == 1:\n",
    "#             imgs_train[count_index_train, ...] = imgs_three_datasets_two_channels[iii, ...]\n",
    "#             imgs_mask_train[count_index_train, ...] = imgs_mask_three_datasets_two_channels[iii, ...]\n",
    "#             count_index_train = count_index_train + 1\n",
    "#         if training_index[iii] == 0:\n",
    "#             imgs_test_selected[count_index_test, ...] = imgs_three_datasets_two_channels[iii, ...]\n",
    "#             imgs_mask_test_selected[count_index_test, ...] = imgs_mask_three_datasets_two_channels[iii, ...]\n",
    "#             count_index_test = count_index_test + 1\n",
    "\n",
    "#     print('training dataset dimension:')\n",
    "#     print(imgs_train.shape[0])\n",
    "#     img_shape=(rows_standard, cols_standard, 2)\n",
    "\n",
    "\n",
    "#     print('-'*30)\n",
    "#     print('Fitting model...')\n",
    "#     print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1033, 200, 200, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(trainlables).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('trainlables.npy', np.asarray(trainlables))    \n",
    "np.save('trainimages.npy', np.asarray(trainimages)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(validationimages).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('validationlables.npy', np.asarray(validationlables))    \n",
    "np.save('validationimages.npy', np.asarray(validationimages)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myshow(img, title=None, margin=0.05, dpi=100):\n",
    "    nda = sitk.GetArrayViewFromImage(img)\n",
    "    spacing = img.GetSpacing()\n",
    "        \n",
    "    if nda.ndim == 3:\n",
    "        # fastest dim, either component or x\n",
    "        c = nda.shape[-1]\n",
    "        \n",
    "        # the the number of components is 3 or 4 consider it an RGB image\n",
    "        if not c in (3,4):\n",
    "            nda = nda[nda.shape[0]//2,:,:]\n",
    "    \n",
    "    elif nda.ndim == 4:\n",
    "        c = nda.shape[-1]\n",
    "        \n",
    "        if not c in (3,4):\n",
    "            raise Runtime(\"Unable to show 3D-vector Image\")\n",
    "            \n",
    "        # take a z-slice\n",
    "        nda = nda[nda.shape[0]//2,:,:,:]\n",
    "            \n",
    "    ysize = nda.shape[0]\n",
    "    xsize = nda.shape[1]\n",
    "      \n",
    "    # Make a figure big enough to accommodate an axis of xpixels by ypixels\n",
    "    # as well as the ticklabels, etc...\n",
    "    figsize = (4 + margin) * ysize / dpi, (4 + margin) * xsize / dpi\n",
    "\n",
    "    fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "    # Make the axis the right size...\n",
    "    ax = fig.add_axes([margin, margin, 1 - 2*margin, 1 - 2*margin])\n",
    "   \n",
    "    extent = (0, xsize*spacing[1], ysize*spacing[0], 0)\n",
    "    \n",
    "    t = ax.imshow(nda,extent=extent,interpolation=None)\n",
    "    \n",
    "    if nda.ndim == 2:\n",
    "        t.set_cmap(\"gray\")\n",
    "    \n",
    "    if(title):\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033, 200, 200, 2) -2.6653488 16.262873\n",
      "(1033, 200, 200, 1) 0.0 1.0\n",
      "(324, 200, 200, 2) -1.9722795 7.7884636\n",
      "(324, 200, 200, 1) 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "X = np.load('trainimages.npy')\n",
    "y = np.load('trainlables.npy')\n",
    "y[y >1] = 0\n",
    "print(X.shape, X.min(), X.max()) # (240, 240, 4) -0.380588 2.62761\n",
    "print(y.shape, y.min(), y.max()) # (240, 240, 1) 0 1 \n",
    "\n",
    "Xtest = np.load('validationimages.npy')\n",
    "ytest = np.load('validationlables.npy')\n",
    "ytest[ytest >1] = 0\n",
    "print(Xtest.shape, Xtest.min(), Xtest.max()) # (240, 240, 4) -0.380588 2.62761\n",
    "print(ytest.shape, ytest.min(), ytest.max()) # (240, 240, 1) 0 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033, 200, 200, 2)\n",
      "(1033, 200, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "def shuffle_list(*ls):\n",
    "    l =list(zip(*ls))\n",
    "    shuffle(l)\n",
    "    return zip(*l)\n",
    "\n",
    "Xs,ys = shuffle_list(X,y)\n",
    "Xs= np.array(Xs)\n",
    "ys= np.array(ys)\n",
    "print(Xs.shape)\n",
    "print(ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose,ZeroPadding2D, Dropout,UpSampling2D,Activation, Cropping2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef_for_training(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.-dice_coef_for_training(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_bn_relu(nd, k=3, inputs=None):\n",
    "    conv = Conv2D(nd, k, padding='same')(inputs) #, kernel_initializer='he_normal'\n",
    "    #bn = BatchNormalization()(conv)\n",
    "    relu = Activation('relu')(conv)\n",
    "    return relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_crop_shape(target, refer):\n",
    "        # width, the 3rd dimension\n",
    "        cw = (target.get_shape()[2] - refer.get_shape()[2]).value\n",
    "        assert (cw >= 0)\n",
    "        if cw % 2 != 0:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "        else:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2)\n",
    "        # height, the 2nd dimension\n",
    "        ch = (target.get_shape()[1] - refer.get_shape()[1]).value\n",
    "        assert (ch >= 0)\n",
    "        if ch % 2 != 0:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "        else:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "        return (ch1, ch2), (cw1, cw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unet():\n",
    "    concat_axis = -1\n",
    "    filters = 3\n",
    "    inputs = Input(batchShape[1:])    \n",
    "    conv1 = conv_bn_relu(64, filters, inputs)\n",
    "    conv1 = conv_bn_relu(64, filters, conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = conv_bn_relu(96, 3, pool1)\n",
    "    conv2 = conv_bn_relu(96, 3, conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = conv_bn_relu(128, 3, pool2)\n",
    "    conv3 = conv_bn_relu(128, 3, conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = conv_bn_relu(256, 3, pool3)\n",
    "    conv4 = conv_bn_relu(256, 4, conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = conv_bn_relu(512, 3, pool4)\n",
    "    conv5 = conv_bn_relu(512, 3, conv5)\n",
    "\n",
    "    up_conv5 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    ch, cw = get_crop_shape(conv4, up_conv5)\n",
    "    crop_conv4 = Cropping2D(cropping=(ch,cw))(conv4)\n",
    "    up6 = concatenate([up_conv5, crop_conv4], axis=concat_axis)\n",
    "    conv6 = conv_bn_relu(256, 3, up6)\n",
    "    conv6 = conv_bn_relu(256, 3, conv6)\n",
    "\n",
    "    up_conv6 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    ch, cw = get_crop_shape(conv3, up_conv6)\n",
    "    crop_conv3 = Cropping2D(cropping=(ch,cw))(conv3)\n",
    "    up7 = concatenate([up_conv6, crop_conv3], axis=concat_axis)\n",
    "    conv7 = conv_bn_relu(128, 3, up7)\n",
    "    conv7 = conv_bn_relu(128, 3, conv7)\n",
    "\n",
    "    up_conv7 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    ch, cw = get_crop_shape(conv2, up_conv7)\n",
    "    crop_conv2 = Cropping2D(cropping=(ch,cw))(conv2)\n",
    "    up8 = concatenate([up_conv7, crop_conv2], axis=concat_axis)\n",
    "    conv8 = conv_bn_relu(96, 3, up8)\n",
    "    conv8 = conv_bn_relu(96, 3, conv8)\n",
    "\n",
    "    up_conv8 = UpSampling2D(size=(2, 2))(conv8)\n",
    "    ch, cw = get_crop_shape(conv1, up_conv8)\n",
    "    crop_conv1 = Cropping2D(cropping=(ch,cw))(conv1)\n",
    "    up9 = concatenate([up_conv8, crop_conv1], axis=concat_axis)\n",
    "    conv9 = conv_bn_relu(64, 3, up9)\n",
    "    conv9 = conv_bn_relu(64, 3, conv9)\n",
    "\n",
    "    ch, cw = get_crop_shape(inputs, conv9)\n",
    "    conv9 = ZeroPadding2D(padding=(ch, cw))(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid', padding='same')(conv9) #, kernel_initializer='he_normal'\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    model.compile(optimizer=Adam(lr=(2e-4)), loss=dice_coef_loss)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows =240\n",
    "img_cols =240\n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "batchSize = 20\n",
    "batchShape = (batchSize, 240,240, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(imgs):\n",
    "#   print(\"pree\",imgs.shape, imgs.shape[:-1])\n",
    "    imgs_p = np.ndarray((imgs.shape[0],img_rows, img_cols,imgs.shape[-1]), dtype=np.uint8)\n",
    "#     print(\"imgs.shape[0]\",imgs.shape[0])\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i],(img_cols, img_rows,imgs.shape[-1]), preserve_range=True)\n",
    "  \n",
    "#   print(\"imgs_p\",imgs_p.shape)\n",
    "    return imgs_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X,y):\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-'*30)\n",
    "    imgs_train, imgs_mask_train = np.array(X), np.array(y)#load_train_data()\n",
    "#     myshow(sitk.GetImageFromArray(imgs_train[:,:,0]))\n",
    "#     myshow(sitk.GetImageFromArray(imgs_train[:,:,1]))\n",
    "#     myshow(sitk.GetImageFromArray(imgs_mask_train))\n",
    "#     print(\"shape before\",imgs_train.shape,imgs_mask_train.shape)\n",
    "#     myshow(sitk.GetImageFromArray(imgs_train))\n",
    "\n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    "#     print(\"shapeagfter\",imgs_train.shape,imgs_mask_train.shape)\n",
    "#     myshow(sitk.GetImageFromArray(imgs_train))\n",
    "\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = get_unet()\n",
    "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "# #     myshow(sitk.GetImageFromArray(imgs_train))\n",
    "#     myshow(sitk.GetImageFromArray(imgs_mask_train))\n",
    "#     print(\"before model\",imgs_train.shape,imgs_mask_train.shape)\n",
    "    model.fit(imgs_train, imgs_mask_train, batch_size=20, nb_epoch=2, verbose=1, shuffle=True,\n",
    "              validation_split=0.2,\n",
    "              callbacks=[model_checkpoint])\n",
    "    \n",
    "    return model\n",
    "   \n",
    "def predict(model):    \n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-'*30)\n",
    "    testrange = range(len(ytest))\n",
    "    imgs_test, imgs_id_test = Xtest[:50,:,:,:], ytest[:50,:,:,:]\n",
    "#     print(\"before test pre\",imgs_test.shape,imgs_id_test)\n",
    "    imgs_test = preprocess(imgs_test)\n",
    "#     print(\"after test pre\",imgs_test.shape,imgs_id_test)\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    mean = np.mean(imgs_test)  # mean for data centering\n",
    "    std = np.std(imgs_test)  # std for data normalization\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-'*30)\n",
    "    model.load_weights('weights.h5')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-'*30)\n",
    "#     print(\"test model\",imgs_test.shape)\n",
    "    imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "    print(\"test model finished\",imgs_mask_test.shape)\n",
    "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "    myshow(sitk.GetImageFromArray(imgs_test[20,:,:,1]))\n",
    "    myshow(sitk.GetImageFromArray(imgs_id_test[20,:,:,0]))\n",
    "    myshow(sitk.GetImageFromArray(imgs_mask_test[20,:,:,0]))\n",
    "    print('-' * 30)\n",
    "    print('Saving predicted masks to files...')\n",
    "    print('-' * 30)\n",
    "    pred_dir = 'preds'\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "    for image, image_id in zip(imgs_mask_test, testrange):\n",
    "#         print(image_id)\n",
    "        nn = 0\n",
    "#         print(image.shape)\n",
    "        image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "        imsave(os.path.join(pred_dir,str(image_id) + '_pred.png'), image)\n",
    "        nn+=1\n",
    "    print(imgs_id_test.shape,imgs_mask_test.shape)\n",
    "    return imgs_id_test,imgs_mask_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn= 30\n",
    "Xchunks = [Xs[x:x+nn] for x in range(0, len(Xs), nn)]\n",
    "ychunks = [ys[x:x+nn] for x in range(0, len(ys), nn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Loading and preprocessing train data...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingqin/venv3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jingqin/venv3/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 240, 240, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 240, 240, 64) 1216        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 240, 240, 64) 0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 240, 240, 64) 36928       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 240, 240, 64) 0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 120, 120, 64) 0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 120, 120, 96) 55392       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 120, 120, 96) 0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 120, 120, 96) 83040       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 120, 120, 96) 0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 60, 60, 96)   0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 60, 60, 128)  110720      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 60, 60, 128)  0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 60, 60, 128)  147584      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 60, 60, 128)  0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 30, 30, 128)  0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 30, 30, 256)  295168      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 30, 30, 256)  0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 30, 30, 256)  1048832     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 30, 30, 256)  0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 15, 15, 256)  0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 15, 15, 512)  1180160     max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 15, 15, 512)  0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 15, 15, 512)  2359808     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 15, 15, 512)  0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 30, 30, 512)  0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_9 (Cropping2D)       (None, 30, 30, 256)  0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 30, 30, 768)  0           up_sampling2d_9[0][0]            \n",
      "                                                                 cropping2d_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 30, 30, 256)  1769728     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 30, 30, 256)  0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 30, 30, 256)  590080      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 30, 30, 256)  0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 60, 60, 256)  0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_10 (Cropping2D)      (None, 60, 60, 128)  0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 60, 60, 384)  0           up_sampling2d_10[0][0]           \n",
      "                                                                 cropping2d_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 60, 60, 128)  442496      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 60, 60, 128)  0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 60, 60, 128)  147584      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 60, 60, 128)  0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 120, 120, 128 0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_11 (Cropping2D)      (None, 120, 120, 96) 0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 120, 120, 224 0           up_sampling2d_11[0][0]           \n",
      "                                                                 cropping2d_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 120, 120, 96) 193632      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 120, 120, 96) 0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 120, 120, 96) 83040       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 120, 120, 96) 0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 240, 240, 96) 0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_12 (Cropping2D)      (None, 240, 240, 64) 0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 240, 240, 160 0           up_sampling2d_12[0][0]           \n",
      "                                                                 cropping2d_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 240, 240, 64) 92224       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 240, 240, 64) 0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 240, 240, 64) 36928       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 240, 240, 64) 0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 240, 240, 64) 0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 240, 240, 1)  65          zero_padding2d_3[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 8,674,625\n",
      "Trainable params: 8,674,625\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingqin/venv3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24 samples, validate on 6 samples\n",
      "Epoch 1/2\n",
      "24/24 [==============================] - 208s 9s/step - loss: 0.9974 - val_loss: 0.9948\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 151s 6s/step - loss: 0.9972 - val_loss: 0.9946\n",
      "------------------------------\n",
      "Loading and preprocessing train data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 240, 240, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 240, 240, 64) 1216        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 240, 240, 64) 0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 240, 240, 64) 36928       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 240, 240, 64) 0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 120, 120, 64) 0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 120, 120, 96) 55392       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 120, 120, 96) 0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 120, 120, 96) 83040       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 120, 120, 96) 0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 60, 60, 96)   0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 60, 60, 128)  110720      max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 60, 60, 128)  0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 60, 60, 128)  147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 60, 60, 128)  0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 30, 30, 128)  0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 30, 30, 256)  295168      max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 30, 30, 256)  0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 30, 30, 256)  1048832     activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 30, 30, 256)  0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 15, 15, 256)  0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 15, 15, 512)  1180160     max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 15, 15, 512)  0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 15, 15, 512)  2359808     activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 15, 15, 512)  0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling2D) (None, 30, 30, 512)  0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_13 (Cropping2D)      (None, 30, 30, 256)  0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 30, 30, 768)  0           up_sampling2d_13[0][0]           \n",
      "                                                                 cropping2d_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 30, 30, 256)  1769728     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 30, 30, 256)  0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 30, 30, 256)  590080      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 30, 30, 256)  0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling2D) (None, 60, 60, 256)  0           activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_14 (Cropping2D)      (None, 60, 60, 128)  0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 60, 60, 384)  0           up_sampling2d_14[0][0]           \n",
      "                                                                 cropping2d_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 60, 60, 128)  442496      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 60, 60, 128)  0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 60, 60, 128)  147584      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 60, 60, 128)  0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling2D) (None, 120, 120, 128 0           activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_15 (Cropping2D)      (None, 120, 120, 96) 0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 120, 120, 224 0           up_sampling2d_15[0][0]           \n",
      "                                                                 cropping2d_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 120, 120, 96) 193632      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 120, 120, 96) 0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 120, 120, 96) 83040       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 120, 120, 96) 0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling2D) (None, 240, 240, 96) 0           activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_16 (Cropping2D)      (None, 240, 240, 64) 0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 240, 240, 160 0           up_sampling2d_16[0][0]           \n",
      "                                                                 cropping2d_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 240, 240, 64) 92224       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 240, 240, 64) 0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 240, 240, 64) 36928       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 240, 240, 64) 0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 240, 240, 64) 0           activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 240, 240, 1)  65          zero_padding2d_4[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 8,674,625\n",
      "Trainable params: 8,674,625\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24 samples, validate on 6 samples\n",
      "Epoch 1/2\n",
      "24/24 [==============================] - 150s 6s/step - loss: 0.9863 - val_loss: 0.9903\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 129s 5s/step - loss: 0.9855 - val_loss: 0.9897\n",
      "------------------------------\n",
      "Loading and preprocessing test data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Loading saved weights...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Predicting masks on test data...\n",
      "------------------------------\n",
      " 96/324 [=======>......................] - ETA: 42:22"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-7c60565c5bf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     model = train(Xchunks[2],ychunks[2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtestFilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultFilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-95-3b7029398974>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m#     print(\"test model\",imgs_test.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mimgs_mask_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test model finished\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgs_mask_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imgs_mask_test.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs_mask_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingqin/venv3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1790\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/Users/jingqin/venv3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingqin/venv3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingqin/venv3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingqin/venv3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingqin/venv3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingqin/venv3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingqin/venv3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jingqin/venv3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "if __name__ == '__main__':\n",
    "    for i,j in zip(Xchunks[:2],ychunks[:2]):\n",
    "        model = train(i,j)\n",
    "        models.append(model)\n",
    "#     model = train(Xchunks[2],ychunks[2])\n",
    "    for model in models:\n",
    "        testFilename, resultFilename = predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Loading and preprocessing test data...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingqin/venv3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/jingqin/venv3/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Loading saved weights...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Predicting masks on test data...\n",
      "------------------------------\n",
      "50/50 [==============================] - 307s 6s/step\n",
      "test model finished (50, 240, 240, 1)\n",
      "------------------------------\n",
      "Saving predicted masks to files...\n",
      "------------------------------\n",
      "(50, 200, 200, 1) (50, 240, 240, 1)\n",
      "------------------------------\n",
      "Loading and preprocessing test data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Loading saved weights...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Predicting masks on test data...\n",
      "------------------------------\n",
      "50/50 [==============================] - 338s 7s/step\n",
      "test model finished (50, 240, 240, 1)\n",
      "------------------------------\n",
      "Saving predicted masks to files...\n",
      "------------------------------\n",
      "(50, 200, 200, 1) (50, 240, 240, 1)\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "        testFilename, resultFilename = predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
