{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codes for validating the WMH Challenge training Datasets. The algorithm won the WMH Challenge.\n",
    "#Codes are written by Mr. Hongwei Li (h.l.li@dundee.ac.uk), Mr. Gongfa Jiang and Miss. Zhaolei Wang from Sun Yat-sen University and University of Dundee.\n",
    "#\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import difflib\n",
    "import SimpleITK as sitk\n",
    "import scipy.spatial\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Cropping2D, ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "# from evaluation import getDSC, getHausdorff, getLesionDetection, getAVD, getImages  #please download evaluation.py from the WMH website\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "# from show import imshow\n",
    "from scipy import ndimage\n",
    "#from sklearn.utils import class_weight\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "# import plotly.plotly as py\n",
    "# import plotly.figure_factory as ff\n",
    "# import plotly.graph_objs as go \n",
    "\n",
    "### ----define loss function for U-net ------------\n",
    "smooth = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Utrecht_preprocessing(FLAIR_image, T1_image):\n",
    "\n",
    "    channel_num = 2\n",
    "    print(np.shape(FLAIR_image))\n",
    "    num_selected_slice = np.shape(FLAIR_image)[0]\n",
    "    image_rows_Dataset = np.shape(FLAIR_image)[1]\n",
    "    image_cols_Dataset = np.shape(FLAIR_image)[2]\n",
    "    T1_image = np.float32(T1_image)\n",
    "\n",
    "    brain_mask_FLAIR = np.ndarray((np.shape(FLAIR_image)[0],image_rows_Dataset, image_cols_Dataset), dtype=np.float32)\n",
    "    brain_mask_T1 = np.ndarray((np.shape(FLAIR_image)[0],image_rows_Dataset, image_cols_Dataset), dtype=np.float32)\n",
    "    imgs_two_channels = np.ndarray((num_selected_slice, rows_standard, cols_standard, channel_num), dtype=np.float32)\n",
    "    imgs_mask_two_channels = np.ndarray((num_selected_slice, rows_standard, cols_standard,1), dtype=np.float32)\n",
    "\n",
    "    # FLAIR --------------------------------------------\n",
    "    brain_mask_FLAIR[FLAIR_image >=thresh_FLAIR] = 1\n",
    "    brain_mask_FLAIR[FLAIR_image < thresh_FLAIR] = 0\n",
    "    for iii in range(np.shape(FLAIR_image)[0]):\n",
    "        brain_mask_FLAIR[iii,:,:] = scipy.ndimage.morphology.binary_fill_holes(brain_mask_FLAIR[iii,:,:])  #fill the holes inside brain\n",
    "    print(int(image_rows_Dataset/2-rows_standard/2),int(image_rows_Dataset/2+rows_standard/2), int(image_cols_Dataset/2-cols_standard/2),int(image_cols_Dataset/2+cols_standard/2))\n",
    "    print(FLAIR_image.shape)\n",
    "    \n",
    "    FLAIR_image = FLAIR_image[:, int(image_rows_Dataset/2-rows_standard/2):int(image_rows_Dataset/2+rows_standard/2), int(image_cols_Dataset/2-cols_standard/2):int(image_cols_Dataset/2+cols_standard/2)]\n",
    "    brain_mask_FLAIR = brain_mask_FLAIR[:, int(image_rows_Dataset/2-rows_standard/2):int(image_rows_Dataset/2+rows_standard/2), int(image_cols_Dataset/2-cols_standard/2):int(image_cols_Dataset/2+cols_standard/2)]\n",
    "    ###------Gaussion Normalization here\n",
    "    FLAIR_image -=np.mean(FLAIR_image[brain_mask_FLAIR == 1])      #Gaussion Normalization\n",
    "    FLAIR_image /=np.std(FLAIR_image[brain_mask_FLAIR == 1])\n",
    "    # T1 -----------------------------------------------\n",
    "    brain_mask_T1[T1_image >=thresh_T1] = 1\n",
    "    brain_mask_T1[T1_image < thresh_T1] = 0\n",
    "    for iii in range(np.shape(T1_image)[0]):\n",
    "        brain_mask_T1[iii,:,:] = scipy.ndimage.morphology.binary_fill_holes(brain_mask_T1[iii,:,:])  #fill the holes inside brain\n",
    "    T1_image = T1_image[:, int(image_rows_Dataset/2-rows_standard/2):int(image_rows_Dataset/2+rows_standard/2), int(image_cols_Dataset/2-cols_standard/2):int(image_cols_Dataset/2+cols_standard/2)]\n",
    "    brain_mask_T1 = brain_mask_T1[:, int(image_rows_Dataset/2-rows_standard/2):int(image_rows_Dataset/2+rows_standard/2), int(image_cols_Dataset/2-cols_standard/2):int(image_cols_Dataset/2+cols_standard/2)]\n",
    "    #------Gaussion Normalization\n",
    "    T1_image -=np.mean(T1_image[brain_mask_T1 == 1])      \n",
    "    T1_image /=np.std(T1_image[brain_mask_T1 == 1])\n",
    "    #---------------------------------------------------\n",
    "    FLAIR_image  = FLAIR_image[..., np.newaxis]\n",
    "    T1_image  = T1_image[..., np.newaxis]\n",
    "    imgs_two_channels = np.concatenate((FLAIR_image, T1_image), axis = 3)\n",
    "    print(np.shape(imgs_two_channels))\n",
    "    return imgs_two_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Utrecht_postprocessing(FLAIR_array, pred):\n",
    "    start_slice = 6\n",
    "    num_selected_slice = np.shape(FLAIR_array)[0]\n",
    "    image_rows_Dataset = np.shape(FLAIR_array)[1]\n",
    "    image_cols_Dataset = np.shape(FLAIR_array)[2]\n",
    "    original_pred = np.ndarray(np.shape(FLAIR_array), dtype=np.float32)\n",
    "    original_pred[:,(image_rows_Dataset-rows_standard)/2:(image_rows_Dataset+rows_standard)/2,(image_cols_Dataset-cols_standard)/2:(image_cols_Dataset+cols_standard)/2] = pred[:,:,:,0]\n",
    "    \n",
    "    original_pred[0:start_slice, :, :] = 0\n",
    "    original_pred[(num_selected_slice-start_slice-1):(num_selected_slice-1), :, :] = 0\n",
    "    return original_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GE3T_preprocessing(FLAIR_image, T1_image):\n",
    "\n",
    "  #  start_slice = 10\n",
    "    channel_num = 2\n",
    "    start_cut = 46\n",
    "    print(np.shape(FLAIR_image))\n",
    "    num_selected_slice = np.shape(FLAIR_image)[0]\n",
    "    image_rows_Dataset = np.shape(FLAIR_image)[1]\n",
    "    image_cols_Dataset = np.shape(FLAIR_image)[2]\n",
    "    FLAIR_image = np.float32(FLAIR_image)\n",
    "    T1_image = np.float32(T1_image)\n",
    "\n",
    "    brain_mask_FLAIR = np.ndarray((np.shape(FLAIR_image)[0],image_rows_Dataset, image_cols_Dataset), dtype=np.float32)\n",
    "    brain_mask_T1 = np.ndarray((np.shape(FLAIR_image)[0],image_rows_Dataset, image_cols_Dataset), dtype=np.float32)\n",
    "    imgs_two_channels = np.ndarray((num_selected_slice, rows_standard, cols_standard, channel_num), dtype=np.float32)\n",
    "    imgs_mask_two_channels = np.ndarray((num_selected_slice, rows_standard, cols_standard,1), dtype=np.float32)\n",
    "    FLAIR_image_suitable = np.ndarray((num_selected_slice, rows_standard, cols_standard), dtype=np.float32)\n",
    "    T1_image_suitable = np.ndarray((num_selected_slice, rows_standard, cols_standard), dtype=np.float32)\n",
    "\n",
    "    # FLAIR --------------------------------------------\n",
    "    brain_mask_FLAIR[FLAIR_image >=thresh_FLAIR] = 1\n",
    "    brain_mask_FLAIR[FLAIR_image < thresh_FLAIR] = 0\n",
    "    for iii in range(np.shape(FLAIR_image)[0]):\n",
    "  \n",
    "        brain_mask_FLAIR[iii,:,:] = scipy.ndimage.morphology.binary_fill_holes(brain_mask_FLAIR[iii,:,:])  #fill the holes inside brain\n",
    "        #------Gaussion Normalization\n",
    "    FLAIR_image -=np.mean(FLAIR_image[brain_mask_FLAIR == 1])      #Gaussion Normalization\n",
    "    FLAIR_image /=np.std(FLAIR_image[brain_mask_FLAIR == 1])\n",
    "\n",
    "    FLAIR_image_suitable[...] = np.min(FLAIR_image)\n",
    "    FLAIR_image_suitable[:, :, int(cols_standard/2-image_cols_Dataset/2):int(cols_standard/2+image_cols_Dataset/2)] = FLAIR_image[:, start_cut:start_cut+rows_standard, :]\n",
    "   \n",
    "    # T1 -----------------------------------------------\n",
    "    brain_mask_T1[T1_image >=thresh_T1] = 1\n",
    "    brain_mask_T1[T1_image < thresh_T1] = 0\n",
    "    for iii in range(np.shape(T1_image)[0]):\n",
    " \n",
    "        brain_mask_T1[iii,:,:] = scipy.ndimage.morphology.binary_fill_holes(brain_mask_T1[iii,:,:])  #fill the holes inside brain\n",
    "        #------Gaussion Normalization\n",
    "    T1_image -=np.mean(T1_image[brain_mask_T1 == 1])      #Gaussion Normalization\n",
    "    T1_image /=np.std(T1_image[brain_mask_T1 == 1])\n",
    "\n",
    "    T1_image_suitable[...] = np.min(T1_image)\n",
    "    T1_image_suitable[:, :, int((cols_standard-image_cols_Dataset)/2):int((cols_standard+image_cols_Dataset)/2)] = T1_image[:, start_cut:start_cut+rows_standard, :]\n",
    "    #---------------------------------------------------\n",
    "    FLAIR_image_suitable  = FLAIR_image_suitable[..., np.newaxis]\n",
    "    T1_image_suitable  = T1_image_suitable[..., np.newaxis]\n",
    "    \n",
    "    imgs_two_channels = np.concatenate((FLAIR_image_suitable, T1_image_suitable), axis = 3)\n",
    "    print(np.shape(imgs_two_channels))\n",
    "    return imgs_two_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(3/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GE3T_postprocessing(FLAIR_array, pred):\n",
    "    start_slice = 11\n",
    "    start_cut = 46\n",
    "    num_selected_slice = np.shape(FLAIR_array)[0]\n",
    "    image_rows_Dataset = np.shape(FLAIR_array)[1]\n",
    "    image_cols_Dataset = np.shape(FLAIR_array)[2]\n",
    "    original_pred = np.ndarray(np.shape(FLAIR_array), dtype=np.float32)\n",
    "    original_pred[:, start_cut:start_cut+rows_standard,:] = pred[:,:, (rows_standard-image_cols_Dataset)/2:(rows_standard+image_cols_Dataset)/2,0]\n",
    "\n",
    "    original_pred[0:start_slice, :, :] = 0\n",
    "    original_pred[(num_selected_slice-start_slice-1):(num_selected_slice-1), :, :] = 0\n",
    "    return original_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_name is:\n",
      "11\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "17\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "19\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "2\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "25\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "27\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "29\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "33\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "37\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "39\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "4\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "41\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "49\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "6\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "8\n",
      "From Utrecht!\n",
      "(48, 240, 240)\n",
      "20 220 20 220\n",
      "(48, 240, 240)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "51\n",
      "From Singapore!\n",
      "(48, 232, 256)\n",
      "16 216 28 228\n",
      "(48, 232, 256)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "52\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "53\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "54\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "57\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "58\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "59\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "61\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "63\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "64\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "65\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "66\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "67\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "68\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "69\n",
      "From Singapore!\n",
      "(48, 256, 232)\n",
      "28 228 16 216\n",
      "(48, 256, 232)\n",
      "(48, 200, 200, 2)\n",
      "(48, 200, 200, 2)\n",
      "dir_name is:\n",
      "101\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n",
      "dir_name is:\n",
      "102\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n",
      "dir_name is:\n",
      "103\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n",
      "dir_name is:\n",
      "104\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n",
      "dir_name is:\n",
      "107\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n",
      "dir_name is:\n",
      "108\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n",
      "dir_name is:\n",
      "109\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n",
      "dir_name is:\n",
      "112\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n",
      "dir_name is:\n",
      "114\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n",
      "dir_name is:\n",
      "115\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n",
      "dir_name is:\n",
      "116\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n",
      "dir_name is:\n",
      "126\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n",
      "dir_name is:\n",
      "132\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n",
      "dir_name is:\n",
      "137\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n",
      "dir_name is:\n",
      "144\n",
      "From Amsterdam!\n",
      "(83, 256, 132)\n",
      "(83, 200, 200, 2)\n",
      "(83, 200, 200, 2)\n"
     ]
    }
   ],
   "source": [
    "###---Here comes the main funtion--------------------------------------------\n",
    "###---Leave one patient out validation--------------------------------------------\n",
    "\n",
    "patient_num =45\n",
    "patient_count = 0\n",
    "rows_standard = 200\n",
    "cols_standard = 200\n",
    "thresh_FLAIR = 70      #to mask the brain\n",
    "thresh_T1 = 30\n",
    "para_array = [[0.958, 0.958, 3], [1.00, 1.00, 3], [1.20, 0.977, 3]]    # parameters of the scanner\n",
    "para_array = np.array(para_array, dtype=np.float32)\n",
    "\n",
    "\n",
    "#read the dirs of test data \n",
    "input_dir_1 = '../data/train/Utrecht'\n",
    "input_dir_2 = '../data/train/Singapore'\n",
    "input_dir_3 = '../data/train/Amsterdam'\n",
    "###---dir to save results---------\n",
    "outputDir = 'evaluation_result_LOOV'\n",
    "#-------------------------------------------\n",
    "dirs = os.listdir(input_dir_1) + os.listdir(input_dir_2) + os.listdir(input_dir_3)\n",
    "# #All the slices and the corresponding patients id\n",
    "# imgs_three_datasets_two_channels = np.load('imgs_three_datasets_two_channels.npy')\n",
    "# imgs_mask_three_datasets_two_channels = np.load('imgs_mask_three_datasets_two_channels.npy')\n",
    "# slices_patient_id_label = np.load('slices_patient_id_label.npy')\n",
    "\n",
    "\n",
    "for dir_name in dirs:\n",
    "    print('dir_name is:')\n",
    "    print(dir_name)\n",
    "    \n",
    "    if patient_count < 15:\n",
    "        inputDir = input_dir_1\n",
    "    elif patient_count > 14 and patient_count < 30:\n",
    "        inputDir = input_dir_2\n",
    "    elif patient_count >= 30:\n",
    "        inputDir = input_dir_3\n",
    "    FLAIR_image = sitk.ReadImage(os.path.join(inputDir, dir_name, 'pre', 'FLAIR.nii.gz'))\n",
    "    T1_image = sitk.ReadImage(os.path.join(inputDir, dir_name, 'pre', 'T1.nii.gz'))\n",
    "    \n",
    "    FLAIR_array = sitk.GetArrayFromImage(FLAIR_image)\n",
    "    T1_array = sitk.GetArrayFromImage(T1_image)\n",
    "    #Proccess testing data-----\n",
    "    para_FLAIR = np.ndarray((1,3), dtype=np.float32)\n",
    "    para_FLAIR_ = FLAIR_image.GetSpacing()\n",
    "    para_FLAIR[0,0] = round(para_FLAIR_[0],3)   # get spacing parameters of the data\n",
    "    para_FLAIR[0,1] = round(para_FLAIR_[1],3)  \n",
    "    para_FLAIR[0,2] = round(para_FLAIR_[2],3) \n",
    "    if np.array_equal(para_FLAIR[0], para_array[0]) :\n",
    "        print('From Utrecht!')\n",
    "        imgs_test = Utrecht_preprocessing(FLAIR_array, T1_array)\n",
    "    elif np.array_equal(para_FLAIR[0], para_array[1]):\n",
    "        print('From Singapore!')\n",
    "        imgs_test = Utrecht_preprocessing(FLAIR_array, T1_array)\n",
    "    elif np.array_equal(para_FLAIR[0], para_array[2]):\n",
    "        print('From Amsterdam!')\n",
    "        imgs_test = GE3T_preprocessing(FLAIR_array, T1_array)\n",
    "    print(imgs_test.shape)\n",
    "    patient_count+=1\n",
    "#     ###---train u-net models-------------------------------------------------------------------------------\n",
    "#     training_index = slices_patient_id_label != patient_count\n",
    "#     test_index = slices_patient_id_label == patient_count\n",
    "#     dim_training = sum(training_index)\n",
    "#     dim_test = sum(test_index)\n",
    "#     print('the dim of training set:')\n",
    "#     print(dim_training[0])\n",
    "#     imgs_train = np.ndarray((dim_training[0], rows_standard, cols_standard, 2), dtype=np.float32)\n",
    "#     imgs_test_selected = np.ndarray((dim_test[0], rows_standard, cols_standard, 2), dtype=np.float32)\n",
    "\n",
    "#     imgs_mask_train = np.ndarray((dim_training[0], rows_standard, cols_standard, 1), dtype=np.float32)\n",
    "#     imgs_mask_test_selected = np.ndarray((dim_test[0], rows_standard, cols_standard, 1), dtype=np.float32)\n",
    "#     count_index_train = 0\n",
    "#     count_index_test = 0\n",
    "#     for iii in range(training_index.shape[0]):\n",
    "#         if training_index[iii] == 1:\n",
    "#             imgs_train[count_index_train, ...] = imgs_three_datasets_two_channels[iii, ...]\n",
    "#             imgs_mask_train[count_index_train, ...] = imgs_mask_three_datasets_two_channels[iii, ...]\n",
    "#             count_index_train = count_index_train + 1\n",
    "#         if training_index[iii] == 0:\n",
    "#             imgs_test_selected[count_index_test, ...] = imgs_three_datasets_two_channels[iii, ...]\n",
    "#             imgs_mask_test_selected[count_index_test, ...] = imgs_mask_three_datasets_two_channels[iii, ...]\n",
    "#             count_index_test = count_index_test + 1\n",
    "\n",
    "#     print('training dataset dimension:')\n",
    "#     print(imgs_train.shape[0])\n",
    "#     img_shape=(rows_standard, cols_standard, 2)\n",
    "\n",
    "\n",
    "#     print('-'*30)\n",
    "#     print('Fitting model...')\n",
    "#     print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
